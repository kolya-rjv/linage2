{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2d8c361b-4b32-41a9-9a39-e63a90c7abde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## Load libraries\n",
    "## For survival analysis - using scikit-survival\n",
    "## To make figures - using matplotlib\n",
    "\n",
    "## Clear workspace\n",
    "# (Not needed in Python - variables are local to script)\n",
    "\n",
    "## Fix seed - maintain direction of PCs\n",
    "np.random.seed(111222333)\n",
    "\n",
    "######################################   FUNCTION DEFINITIONS   ############################################\n",
    "## FUNCTIONS START >>> \n",
    "\n",
    "###############################   < READ, WRITE AND CLEAN DATA >  ##########################################\n",
    "\n",
    "def markIncsFromCodeBook(codeBook):\n",
    "    \"\"\"Selects all columns marked as data (\"1\" in Data column) in codebook for inclusion in master dataset\"\"\"\n",
    "    incFlags = codeBook[\"Data\"].values  ## This column is \"1\" for include in dataset, 0 for not (comments or demo data)\n",
    "    incNames = codeBook.iloc[:, 0].astype(str).values\n",
    "    incList = np.column_stack((incNames, incFlags))\n",
    "    return incList\n",
    "\n",
    "\n",
    "def dropCols(dataSet, incList):\n",
    "    \"\"\"Simply drops everything not flagged with 1 in incList (Data)\"\"\"\n",
    "    incInds = np.where(incList[:, 1].astype(int) == 1)[0]\n",
    "    incTerms = incList[:, 0][incInds]\n",
    "    nTerms = len(incTerms)\n",
    "    \n",
    "    ## The first column is always the subject number (SEQN) - add that back\n",
    "    outData = dataSet.iloc[:, 0:1].copy()\n",
    "    \n",
    "    for i in range(1, nTerms):\n",
    "        ## loop over terms that have a \"1\" in column 2 of the incList, find those in\n",
    "        ## dataSet and include in output dataSet\n",
    "        nextTerm = incTerms[i]\n",
    "        if nextTerm in dataSet.columns:\n",
    "            nextCol = dataSet[nextTerm]\n",
    "            outData = pd.concat([outData, nextCol], axis=1)\n",
    "    \n",
    "    ## Name first column appropriately and return resulting dataset\n",
    "    outData.columns = ['SEQN'] + list(outData.columns[1:])\n",
    "    return outData\n",
    "\n",
    "\n",
    "def dropNAcolumns(dataSet, pNAcut, incSwitch, verbose):\n",
    "    \"\"\"This takes a single cutoff fraction and drops all columns (features)\n",
    "    that contain more NAs than allowed by the cutoff.\n",
    "    However, if force include flag is set (==1) for a column, we will force the inclusion of feature\"\"\"\n",
    "    \n",
    "    nRows = dataSet.shape[0]\n",
    "    nCols = dataSet.shape[1]\n",
    "    forceFlags = np.zeros(nCols)\n",
    "    \n",
    "    ## If incSwitch IS set, we read them from the codebook\n",
    "    if incSwitch == 1:\n",
    "        ## Read include flags from codebook\n",
    "        codeBookFlags = codeBook['ForceInc'].values\n",
    "        ## Identify column terms that we cannot drop\n",
    "        nForced = np.sum(codeBookFlags)\n",
    "        forceIncTerms = codeBook['Var'][codeBookFlags == 1].values\n",
    "        ## Now identify columns in dataset that need to be retained\n",
    "        for i in range(nForced):\n",
    "            nextTerm = forceIncTerms[i]\n",
    "            if nextTerm in dataSet.columns:\n",
    "                forceThis = dataSet.columns.get_loc(nextTerm)\n",
    "                ## Flip the respective forceFlag to 1 - this column cannot be dropped\n",
    "                nrOfNAs = dataSet.iloc[:, forceThis].isna().sum()\n",
    "                if verbose:\n",
    "                    print(f\"Applying force flag to: {nextTerm}\")\n",
    "                    print(f\"\\t - this will include:\\t {nrOfNAs}\\t NAs in:\\t {nRows}  {round(nrOfNAs/nRows*100, 2)}%\")\n",
    "                forceFlags[forceThis] = 1\n",
    "    \n",
    "    ## Now drop all columns with too many NAs\n",
    "    naColSum = dataSet.isna().sum()\n",
    "    naColP = naColSum / nRows\n",
    "    \n",
    "    ## Keep only those columns (features) for which naColP (number of NAs) is smaller than pNAcut\n",
    "    keepCols = naColP < pNAcut\n",
    "    \n",
    "    ## Finally, recover all columns that we decided to force (retain)\n",
    "    ## Merge keepCols (columns that will be kept due to cutoff) and forceFlags\n",
    "    keepCols = keepCols | (forceFlags == 1)\n",
    "    dataSet = dataSet.loc[:, keepCols]\n",
    "    \n",
    "    ## Print dimension of surviving matrix and list of surviving variables\n",
    "    nrows = dataSet.shape[0]\n",
    "    ncols = dataSet.shape[1]\n",
    "    varNames = dataSet.columns\n",
    "    humNames = varNames\n",
    "    \n",
    "    for i in range(1, len(varNames)):\n",
    "        varName = varNames[i]\n",
    "    \n",
    "    return dataSet\n",
    "\n",
    "\n",
    "def qDataMatGen(masterData, incList):\n",
    "    \"\"\"Loop over masterData and keep any column that has a zero in the \"data\" column\"\"\"\n",
    "    allTerms = masterData.columns\n",
    "    nTerms = masterData.shape[1]  ## number of total terms (columns) in masterData\n",
    "    nIncFlags = incList.shape[0]  ## number of terms in codebook - for which we know include flags\n",
    "    \n",
    "    ## The first column of the qDataMatrix has to be SEQN number - add these first\n",
    "    qDataNames = [\"SEQN\"]\n",
    "    qDataMatrix = masterData.iloc[:, 0:1].copy()\n",
    "    \n",
    "    ## Loop over all terms (columns) in masterData - extract one term (column) at a time\n",
    "    for i in range(1, nTerms):\n",
    "        ## look at the next term in the data and get the respective flag from the incList\n",
    "        nextTerm = allTerms[i]\n",
    "        \n",
    "        ## Now loop over all terms in the incList and get the flag for the current term\n",
    "        flag = 0  ## Graceful default is 0 - not include\n",
    "        for j in range(nIncFlags):\n",
    "            if incList[j, 0] == nextTerm:\n",
    "                ## Read the inc flag (second entry of that column) and return it\n",
    "                flag = int(incList[j, 1])\n",
    "        \n",
    "        if flag == 0:\n",
    "            ## If include == 0, we will include that parameter in the qDataMatrix\n",
    "            qDataColumn = masterData.iloc[:, i]  ## Keep the current column for inclusion to qDataMatrix\n",
    "            qDataMatrix = pd.concat([qDataMatrix, qDataColumn], axis=1)  ## Add current column to qDataMatrix\n",
    "            qDataNames.append(nextTerm)  ## Also keep the current column name (nextTerm) as column name\n",
    "    \n",
    "    qDataMatrix.columns = qDataNames  ## Update all column names\n",
    "    return qDataMatrix  ## Return the matrix\n",
    "\n",
    "\n",
    "def getNonNARows(dataSet):\n",
    "    \"\"\"Identify rows that contain NAs and drop them by only retaining those that do not\n",
    "    sums over NAs are NA so only rows with no (zero) NAs return !is.na\"\"\"\n",
    "    keepRows = (dataSet.isna().sum(axis=1) == 0)\n",
    "    return keepRows\n",
    "\n",
    "\n",
    "#########################  < CALCULATING DERIVED FEATURES FROM DATA >  #####################################\n",
    "\n",
    "def popPCFIfs1(qDataMat):\n",
    "    \"\"\"This will calculate our frailty index / disease and comorbidity index for each subject\n",
    "    and populate the matrix\n",
    "    \n",
    "    NOTE: we will allow NAs here - so check that the variables are all there\"\"\"\n",
    "    \n",
    "    BPQ020 = qDataMat[\"BPQ020\"].copy()\n",
    "    DIQ010 = qDataMat[\"DIQ010\"].copy()\n",
    "    HUQ010 = qDataMat[\"HUQ010\"].copy()\n",
    "    HUQ020 = qDataMat[\"HUQ020\"].copy()\n",
    "    HUQ050 = qDataMat[\"HUQ050\"].copy()\n",
    "    HUQ070 = qDataMat[\"HUQ070\"].copy()\n",
    "    KIQ020 = qDataMat[\"KIQ020\"].copy()\n",
    "    MCQ010 = qDataMat[\"MCQ010\"].copy()\n",
    "    MCQ053 = qDataMat[\"MCQ053\"].copy()\n",
    "    MCQ160A = qDataMat[\"MCQ160A\"].copy()\n",
    "    MCQ160B = qDataMat[\"MCQ160B\"].copy()\n",
    "    MCQ160C = qDataMat[\"MCQ160C\"].copy()\n",
    "    MCQ160D = qDataMat[\"MCQ160D\"].copy()\n",
    "    MCQ160E = qDataMat[\"MCQ160E\"].copy()\n",
    "    MCQ160F = qDataMat[\"MCQ160F\"].copy()\n",
    "    MCQ160G = qDataMat[\"MCQ160G\"].copy()\n",
    "    MCQ160I = qDataMat[\"MCQ160I\"].copy()\n",
    "    MCQ160J = qDataMat[\"MCQ160J\"].copy()\n",
    "    MCQ160K = qDataMat[\"MCQ160K\"].copy()\n",
    "    MCQ160L = qDataMat[\"MCQ160L\"].copy()\n",
    "    MCQ220 = qDataMat[\"MCQ220\"].copy()\n",
    "    OSQ010A = qDataMat[\"OSQ010A\"].copy()\n",
    "    OSQ010B = qDataMat[\"OSQ010B\"].copy()\n",
    "    OSQ010C = qDataMat[\"OSQ010C\"].copy()\n",
    "    OSQ060 = qDataMat[\"OSQ060\"].copy()\n",
    "    PFQ056 = qDataMat[\"PFQ056\"].copy()\n",
    "    \n",
    "    ## Give \"safe\" value to all NAs ...\n",
    "    BPQ020.fillna(2, inplace=True)\n",
    "    DIQ010.fillna(2, inplace=True)\n",
    "    HUQ010.fillna(3, inplace=True)\n",
    "    HUQ020.fillna(3, inplace=True)\n",
    "    HUQ050.fillna(0, inplace=True)\n",
    "    HUQ070.fillna(2, inplace=True)\n",
    "    KIQ020.fillna(2, inplace=True)\n",
    "    MCQ010.fillna(2, inplace=True)\n",
    "    MCQ053.fillna(2, inplace=True)\n",
    "    MCQ160A.fillna(2, inplace=True)\n",
    "    MCQ160B.fillna(2, inplace=True)\n",
    "    MCQ160C.fillna(2, inplace=True)\n",
    "    MCQ160D.fillna(2, inplace=True)\n",
    "    MCQ160E.fillna(2, inplace=True)\n",
    "    MCQ160F.fillna(2, inplace=True)\n",
    "    MCQ160G.fillna(2, inplace=True)\n",
    "    MCQ160I.fillna(2, inplace=True)\n",
    "    MCQ160J.fillna(2, inplace=True)\n",
    "    MCQ160K.fillna(2, inplace=True)\n",
    "    MCQ160L.fillna(2, inplace=True)\n",
    "    MCQ220.fillna(2, inplace=True)\n",
    "    OSQ010A.fillna(2, inplace=True)\n",
    "    OSQ010B.fillna(2, inplace=True)\n",
    "    OSQ010C.fillna(2, inplace=True)\n",
    "    OSQ060.fillna(2, inplace=True)\n",
    "    PFQ056.fillna(2, inplace=True)\n",
    "    \n",
    "    ## Binary yes/no decision vector\n",
    "    binVec = np.column_stack([\n",
    "        (BPQ020 == 1), ((DIQ010 == 1) | (DIQ010 == 3)), (KIQ020 == 1), (MCQ010 == 1), (MCQ053 == 1),\n",
    "        (MCQ160A == 1), (MCQ160C == 1), (MCQ160D == 1), (MCQ160E == 1), (MCQ160F == 1),\n",
    "        (MCQ160G == 1), (MCQ160I == 1), (MCQ160J == 1), (MCQ160K == 1), (MCQ160L == 1),\n",
    "        (MCQ220 == 1), (OSQ010A == 1), (OSQ010B == 1), (OSQ010C == 1), (OSQ060 == 1),\n",
    "        (PFQ056 == 1), (HUQ070 == 1)\n",
    "    ])\n",
    "    \n",
    "    sumOverBinVec = binVec.sum(axis=1) / 22\n",
    "    return sumOverBinVec\n",
    "\n",
    "\n",
    "def popPCFIfs2(qDataMat):\n",
    "    \n",
    "    HUQ010 = qDataMat[\"HUQ010\"].copy()\n",
    "    HUQ020 = qDataMat[\"HUQ020\"].copy()\n",
    "    HUQ010.fillna(3, inplace=True)\n",
    "    HUQ020.fillna(3, inplace=True)\n",
    "    \n",
    "    ## If sick/feeling bad, get score of 2 to 4 - if getting worse -> get 2x modifier\n",
    "    ## if getting better -> 1/2 modifier\n",
    "    aVec = ((HUQ010 == 4) * 2 + (HUQ010 == 5) * 4)\n",
    "    dVec = (1 - (HUQ020 == 1) * 0.5 + (HUQ020 == 2))\n",
    "    fScore = aVec * dVec\n",
    "    \n",
    "    return fScore\n",
    "\n",
    "\n",
    "def popPCFIfs3(qDataMat):\n",
    "    \"\"\"This basically codes NHANES HUQ050: \"Number times received healthcare over past year\" \"\"\"\n",
    "    HUQ050 = qDataMat[\"HUQ050\"].copy()\n",
    "    HUQ050.fillna(0, inplace=True)\n",
    "    HUQ050[HUQ050 == 77] = 0  ## Comment codes (\"Refused\")\n",
    "    HUQ050[HUQ050 == 99] = 0  ## Comment codes (\"Do not know\")\n",
    "    return HUQ050\n",
    "\n",
    "\n",
    "def populateLDL(dataMat, qDataMat):\n",
    "    \"\"\"This function will calculate LDL and adds it to the dataMatrix\n",
    "    LDL - calculated from:\n",
    "       Variable: LBDTCSI\t        Total Cholesterol (mmol/L)\n",
    "       Variable: LBDHDLSI\tHDL (mmol/L)\n",
    "       Variable: LBDSTRSI\tTriglycerides (mmol/L)\n",
    "    Formula:  LDL-C=(TC)–(triglycerides/5)– (HDL-C).\n",
    "    NOTES: Can be inaccurate if triglycerides are very high (above 150 mg/dL)\"\"\"\n",
    "    \n",
    "    nSubs = dataMat.shape[0]\n",
    "    \n",
    "    ## Extract all relevant variables from data matrix\n",
    "    totCv = dataMat[\"LBDTCSI\"].values\n",
    "    HDLv = dataMat[\"LBDHDLSI\"].values\n",
    "    triGv = dataMat[\"LBDSTRSI\"].values\n",
    "    seqVec = dataMat[\"SEQN\"].values\n",
    "    LDLvec = np.zeros(nSubs)\n",
    "    \n",
    "    ## Loop over all subjects and update LDL\n",
    "    for i in range(nSubs):\n",
    "        totC = totCv[i]\n",
    "        HDL = HDLv[i]\n",
    "        TG = triGv[i]\n",
    "        LDL = 0\n",
    "        \n",
    "        ## Check that we do not have any NAs here\n",
    "        # actual condition is supposed to be  ~(np.isnan(totC) or np.isnan(HDL) or np.isnan(TG))\n",
    "        # but we have buggy R prototype and have to replicate that\n",
    "        condition = (not np.isnan(totC)) * (not np.isnan(HDL)) * (not np.isnan(TG))\n",
    "        if condition:\n",
    "            ## Calculate LDL from triglycerides and total cholesterol\n",
    "            LDL = (totC - (TG / 5) - (HDL))\n",
    "        \n",
    "        LDLvec[i] = LDL\n",
    "    \n",
    "    return LDLvec\n",
    "\n",
    "\n",
    "#############################  < DATA SELECTION - ROWS / SUBJECTS >  ####################################\n",
    "\n",
    "def selectAgeBracket(qMat, ageCutLower, ageCutUpper):\n",
    "    \"\"\"Apply a age bracket to dataset - only retain samples between upper and lower age limit\"\"\"\n",
    "    keepRows = ((qMat[\"RIDAGEYR\"] >= ageCutLower) & (qMat[\"RIDAGEYR\"] <= ageCutUpper))\n",
    "    return keepRows\n",
    "\n",
    "\n",
    "def nonAccidDeathFlags(qMat):\n",
    "    \"\"\"Here we will return keep flags for all subjects who die of non-accidental deaths\n",
    "    The cause of death (leading) is recorded (if known) in the questionnaire data matrix\n",
    "    qDatMat in the \"UCOD_LEADING\" column\n",
    "    Possible values in \"UCOD_LEADING\" are:\n",
    "    001 = Disease of the heart\n",
    "    002 = Malignant neoplasm\n",
    "    003 = Chronic lower respiratory disease\n",
    "    004 = Accidents and unintentional injuries\n",
    "    005 = Cerebrovascular disease\n",
    "    007 = Diabetes\n",
    "    008 = Influenza and pneumonia\n",
    "    009 = Nephritis, kidney issues\n",
    "    010 = All other causes (residuals)\n",
    "    NA  = no info (the vast majority of cases)\"\"\"\n",
    "    \n",
    "    ## Extract cause of deaths\n",
    "    causeOfDeath = qMat[\"UCOD_LEADING\"].copy()\n",
    "    ## Then drop NAs (turn into zeros)\n",
    "    causeOfDeath.fillna(0, inplace=True)\n",
    "    keepFlags = causeOfDeath != 4\n",
    "    \n",
    "    return keepFlags\n",
    "\n",
    "\n",
    "def foldOutliers(dataMatNorm, zScoreMax):\n",
    "    \"\"\"Fold in outlier z-scores\"\"\"\n",
    "    \n",
    "    print(f\"> Folding in outliers at maximum total zScore: {zScoreMax}\", end=\"\")\n",
    "    ## Now truncate / fold outliers and show boxplots\n",
    "    \n",
    "    dataMatNorm_folded = dataMatNorm.copy()\n",
    "    allTerms = dataMatNorm.columns[1:]\n",
    "    \n",
    "    for nextTerm in allTerms:\n",
    "        colVals = dataMatNorm[nextTerm].values\n",
    "        if np.isinf(colVals).any():\n",
    "            print(f\"Infinite value in: {nextTerm}\")\n",
    "        ## boxplot(colVals,main=paste(nextTerm,\"-before\"))\n",
    "        foldThese = np.abs(colVals) > zScoreMax\n",
    "        colVals[foldThese] = np.sign(colVals[foldThese]) * zScoreMax\n",
    "        ## boxplot(colVals,main=paste(nextTerm,\"-after\"))\n",
    "        ## readline()\n",
    "        dataMatNorm_folded[nextTerm] = colVals\n",
    "    \n",
    "    print(\" ... Done\")\n",
    "    return dataMatNorm_folded\n",
    "\n",
    "\n",
    "def digiCot(dataMat):\n",
    "    \"\"\"Digitize continine to turn into smoking intensity\n",
    "    Most clinics do not routinely measure cotinine - so here we will\n",
    "    bin cot as follows:\n",
    "    0  <= cot < 10 are non smokers (0)\n",
    "    10 >= cot < 100 are light smokers (1)\n",
    "    100 >= cot < 200 are moderate smokers (2)\n",
    "    anything above 200 is a heavy smoker (3)\"\"\"\n",
    "    \n",
    "    print(\"> Digitizing cotinine data ... \", end=\"\")\n",
    "    cot = dataMat[\"LBXCOT\"].copy()\n",
    "    dataMat_out = dataMat.copy()\n",
    "    dataMat_out.loc[cot < 10, \"LBXCOT\"] = 0\n",
    "    dataMat_out.loc[(cot >= 10) & (cot < 100), \"LBXCOT\"] = 1\n",
    "    dataMat_out.loc[(cot >= 100) & (cot < 200), \"LBXCOT\"] = 2\n",
    "    dataMat_out.loc[cot >= 200, \"LBXCOT\"] = 3\n",
    "    print(\"Done\\n\")\n",
    "    return dataMat_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d9cbab88-0795-4c3a-b1dd-b17c0fe56d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################    MATH AND ANALYSIS FUNCTIONS    #######################################\n",
    "\n",
    "# def normAsZscores_99_young_mf(dataSet, qDataMat, dataSet_ref, qDataMat_ref):\n",
    "#     \"\"\"Normalize by training set (00/99) only\"\"\"\n",
    "    \n",
    "#     seqSel = qDataMat_ref[\"yearsNHANES\"] == 9900\n",
    "    \n",
    "#     ## Select age cutoff\n",
    "#     ageVec = qDataMat_ref[\"RIDAGEYR\"]\n",
    "#     ageSel = ageVec <= 50\n",
    "    \n",
    "#     ## Combine selections - all in reference data only\n",
    "#     selVec = ageSel & seqSel\n",
    "    \n",
    "#     ## extract data matrix\n",
    "#     dataSet_temp = dataSet_ref[selVec]\n",
    "#     ## Sex selection vector - true for males\n",
    "#     sexSel_temp = qDataMat_ref.loc[selVec, \"RIAGENDR\"] == 1  ## Sex selection vector for 1999 to 2000 data only\n",
    "#     sexSel = qDataMat[\"RIAGENDR\"] == 1  ## Sex selection vector for dataset to be normalized\n",
    "    \n",
    "#     ## Normalize data by column average for each column independently\n",
    "#     nRows = dataSet.shape[0]\n",
    "#     nCols = dataSet.shape[1]\n",
    "    \n",
    "#     ## Make normalized matrix by turning each value into z-score\n",
    "#     dataMatN = dataSet.copy()\n",
    "#     ## There is certainly a more elegant way of doing this - but for hackability, lets just do a\n",
    "#     ## simple loop for now - column 1 is still the subject seq number - will not be normalized\n",
    "#     dataMatN.iloc[:, 0] = dataSet.iloc[:, 0]\n",
    "    \n",
    "#     ## We will not apply normalization to some columns - fs scores in particular\n",
    "#     skipCols = [\"fs1Score\", \"fs2Score\", \"fs3Score\", \"LBXCOT\", \"LBDBANO\"]\n",
    "    \n",
    "#     ## Loop over all columns - starting from column 2 (first data col)\n",
    "#     for col in range(1, nCols):\n",
    "#         if dataSet.columns[col] not in skipCols:\n",
    "#             ## Median and MAD - males\n",
    "#             med_m = np.median(dataSet_temp[sexSel_temp].iloc[:, col])\n",
    "#             mad_m = stats.median_abs_deviation(dataSet_temp[sexSel_temp].iloc[:, col], nan_policy='omit')\n",
    "            \n",
    "#             ## Median and MAD - females\n",
    "#             med_f = np.median(dataSet_temp[~sexSel_temp].iloc[:, col])\n",
    "#             mad_f = stats.median_abs_deviation(dataSet_temp[~sexSel_temp].iloc[:, col], nan_policy='omit')\n",
    "            \n",
    "#             ## Loop over all rows in current column and normalize each value by column mean\n",
    "#             for row in range(nRows):\n",
    "#                 ## Determine sex\n",
    "#                 sexNow = int(sexSel.iloc[row])\n",
    "#                 if sexNow == 1:  # This is a male\n",
    "#                     mad = mad_m\n",
    "#                     med = med_m\n",
    "#                 if sexNow == 0:  # This is a female\n",
    "#                     mad = mad_f\n",
    "#                     med = med_f\n",
    "                \n",
    "#                 ## Now calculate z-score for each row of this column - use sex-specific median and MAD values\n",
    "#                 zScore_nonN = (dataSet.iloc[row, col] - med) / mad\n",
    "                \n",
    "#                 ## Store normalized and log2 fold changes (vs. column average) in new matrices\n",
    "#                 dataMatN.iloc[row, col] = zScore_nonN\n",
    "    \n",
    "#     return dataMatN\n",
    "\n",
    "def normAsZscores_99_young_mf(dataSet, qDataMat, dataSet_ref, qDataMat_ref):\n",
    "    \"\"\"Normalize by training set (1999–2000 only), sex-specific median & MAD (R-equivalent).\"\"\"\n",
    "\n",
    "    # --- reference subset: yearsNHANES == 9900 and RIDAGEYR <= 50 ---\n",
    "    years = qDataMat_ref[\"yearsNHANES\"]\n",
    "    seqSel = (years == 9900) | (years.astype(str) == \"9900\")\n",
    "    ageSel = qDataMat_ref[\"RIDAGEYR\"] <= 50\n",
    "    selVec = seqSel & ageSel\n",
    "\n",
    "    dataSet_temp = dataSet_ref.loc[selVec].copy()\n",
    "    sexSel_temp = (qDataMat_ref.loc[selVec, \"RIAGENDR\"] == 1)  # True for males in REF\n",
    "    sexSel = (qDataMat[\"RIAGENDR\"] == 1)                       # True for males in TARGET\n",
    "\n",
    "    nRows, nCols = dataSet.shape\n",
    "    dataMatN = dataSet.copy()\n",
    "\n",
    "    # column 0 stays as-is (e.g., SEQN)\n",
    "    dataMatN.iloc[:, 0] = dataSet.iloc[:, 0]\n",
    "\n",
    "    skipCols = {\"fs1Score\", \"fs2Score\", \"fs3Score\", \"LBXCOT\", \"LBDBANO\"}\n",
    "\n",
    "    def safe_z(x, med, mad_val):\n",
    "        if np.isnan(med) or np.isnan(mad_val):\n",
    "            return np.full_like(x, np.nan, dtype=float)\n",
    "        if mad_val == 0 or np.isclose(mad_val, 0.0):\n",
    "            # exact median -> 0, otherwise NaN (mirrors division-by-zero behavior without infs)\n",
    "            return np.where(np.isfinite(x), np.where(x == med, 0.0, np.nan), np.nan)\n",
    "        return (x - med) / mad_val\n",
    "\n",
    "    for col in range(1, nCols):\n",
    "        name = dataSet.columns[col]\n",
    "        if name in skipCols:\n",
    "            continue\n",
    "\n",
    "        # reference data split by sex (coerce to numeric; NAs are handled downstream)\n",
    "        ref_m = pd.to_numeric(dataSet_temp.loc[sexSel_temp, name], errors=\"coerce\").to_numpy()\n",
    "        ref_f = pd.to_numeric(dataSet_temp.loc[~sexSel_temp, name], errors=\"coerce\").to_numpy()\n",
    "\n",
    "        # NA-robust medians (align with MAD's nan omission)\n",
    "        med_m = np.nanmedian(ref_m)\n",
    "        med_f = np.nanmedian(ref_f)\n",
    "\n",
    "        # MAD with normal-consistent scaling (matches R's mad default), omit NaNs\n",
    "        mad_m = stats.median_abs_deviation(ref_m, scale=\"normal\", nan_policy=\"omit\")\n",
    "        mad_f = stats.median_abs_deviation(ref_f, scale=\"normal\", nan_policy=\"omit\")\n",
    "\n",
    "        # target column values\n",
    "        x = pd.to_numeric(dataSet.iloc[:, col], errors=\"coerce\").to_numpy()\n",
    "\n",
    "        # compute male/female z-scores then merge by target sex\n",
    "        z_m = safe_z(x, med_m, mad_m)\n",
    "        z_f = safe_z(x, med_f, mad_f)\n",
    "        z = np.where(sexSel.to_numpy(), z_m, z_f)\n",
    "\n",
    "        dataMatN.iloc[:, col] = z\n",
    "\n",
    "    return dataMatN\n",
    "\n",
    "def boxCoxTransform(boxCox_lam, dataMat):\n",
    "    \"\"\"Apply box cox transforms based on lambda given\"\"\"\n",
    "    dataMat_out = dataMat.copy()\n",
    "    allTerms = dataMat.columns[1:]\n",
    "    print(\"> Applying boxCox transformed  ... \", end=\"\")\n",
    "    for nextTerm in allTerms:\n",
    "        ## Get column number\n",
    "        dataColNr = dataMat.columns.get_loc(nextTerm)\n",
    "        if nextTerm in boxCox_lam.columns:\n",
    "            lamNr = boxCox_lam.columns.get_loc(nextTerm)\n",
    "            ## Get next transformation\n",
    "            nextLam = boxCox_lam.iloc[0, lamNr]\n",
    "            ## Get next data item (column)\n",
    "            colVals = dataMat[nextTerm].copy()\n",
    "            ## Selection of transformation is based on lambda value\n",
    "            if not pd.isna(nextLam):  ## If NA, do nothing\n",
    "                if nextLam == 0:\n",
    "                    colVals = np.log(colVals)  ## If the lambda value is zero, we log the data column\n",
    "                else:\n",
    "                    colVals = (colVals**nextLam - 1) / nextLam  ## If it is neither NA nor zero - boxCox formula for lambda\n",
    "            dataMat_out[nextTerm] = colVals\n",
    "    \n",
    "    print(\"Done\")\n",
    "    return dataMat_out\n",
    "\n",
    "\n",
    "def projectToSVD(inputMat, svdCoordMat):\n",
    "    \"\"\"Project inputMat data matrix into the same PC coordinates provided by svdCoordMat\"\"\"\n",
    "    \n",
    "    print(\"> Projecting data into PC coordinates  ... \", end=\"\")\n",
    "    mSamples = inputMat.shape[0]\n",
    "    nSVs = svdCoordMat.shape[1]\n",
    "    pcMat = np.zeros((mSamples, nSVs))  ## Empty data matrix in PC coordinates\n",
    "    \n",
    "    ## Doing loop to calculate coordinates for samples in terms of PCs - could do matrix mult instead\n",
    "    for sample in range(mSamples):\n",
    "        ## Current sample is current row of data (input) matrix\n",
    "        curSample = inputMat[sample, :]\n",
    "        \n",
    "        ## Now loop over all nSVs and determine\n",
    "        for pcNr in range(nSVs):\n",
    "            ## current PC vector is the column\n",
    "            curPC = svdCoordMat[:, pcNr]\n",
    "            coord = curSample @ curPC\n",
    "            pcMat[sample, pcNr] = coord\n",
    "    \n",
    "    print(\"Done\")\n",
    "    return pcMat\n",
    "\n",
    "\n",
    "# def getSurvTime(qMatrix):\n",
    "#     \"\"\"Function to calculate survival time between enrollment and end of follow up\n",
    "#     Get the age (in month) at time of initial screen\n",
    "    \n",
    "#     For those individuals who died before the cutoff date in 2019, we have\n",
    "#     information on time between survey and death - for survivors, the entry is time\n",
    "#     between the initial exam and the end of the follow up\n",
    "    \n",
    "#     NOTE: THIS IS REALLY NOT SURVIVAL TIME BUT TIME TO FOLLOW UP - interpret with eventFlags!\"\"\"\n",
    "    \n",
    "#     survTimes = qMatrix[\"PERMTH_EXM\"].values\n",
    "#     return survTimes\n",
    "\n",
    "\n",
    "# def getEventVec(qMatrix, cause):\n",
    "#     \"\"\"Read qDataMatrix and determine if individual died during study period or was censored\n",
    "#     that is, survived beyond the end of the study ...\"\"\"\n",
    "    \n",
    "#     if cause == 0:  ## IF cause is 0, we do not care what people died from and report all deaths\n",
    "#         eventFlags = qMatrix[\"MORTSTAT\"].values\n",
    "#         return eventFlags\n",
    "    \n",
    "#     if cause != 0:  ## If cause is > 0, we will report only specific causes of death\n",
    "#         eventFlags = qMatrix[\"MORTSTAT\"].values\n",
    "#         CODFlags = qMatrix[\"UCOD_LEADING\"].values\n",
    "        \n",
    "#         if cause == 1:  ## Heart disease deaths only\n",
    "#             countThese = (CODFlags == 1)\n",
    "#             eventFlags = eventFlags * countThese\n",
    "#             return eventFlags\n",
    "#         if cause == 2:  ## Cancer deaths only\n",
    "#             countThese = (CODFlags == 2)\n",
    "#             eventFlags = eventFlags * countThese\n",
    "#             return eventFlags\n",
    "#         if cause == 3:  ## COPD deaths only\n",
    "#             countThese = (CODFlags == 3)\n",
    "#             eventFlags = eventFlags * countThese\n",
    "#             return eventFlags\n",
    "#         if cause == 4:  ## Accident deaths only\n",
    "#             countThese = (CODFlags == 4)\n",
    "#             eventFlags = eventFlags * countThese\n",
    "#             return eventFlags\n",
    "#         if cause == 5:  ## Stroke deaths only\n",
    "#             countThese = (CODFlags == 5)\n",
    "#             eventFlags = eventFlags * countThese\n",
    "#             return eventFlags\n",
    "#         if cause == 6:  ## Deaths directly from AD only\n",
    "#             countThese = (CODFlags == 6)\n",
    "#             eventFlags = eventFlags * countThese\n",
    "#             return eventFlags\n",
    "#         if cause == 7:  ## Deaths directly form diabetes only\n",
    "#             countThese = (CODFlags == 7)\n",
    "#             eventFlags = eventFlags * countThese\n",
    "#             return eventFlags\n",
    "#         if cause == 8:  ## Deaths from influenza and pneumonia\n",
    "#             countThese = (CODFlags == 8)\n",
    "#             eventFlags = eventFlags * countThese\n",
    "#             return eventFlags\n",
    "#         if cause == 9:  ## Deaths from kidney issues\n",
    "#             countThese = (CODFlags == 9)\n",
    "#             eventFlags = eventFlags * countThese\n",
    "#             return eventFlags\n",
    "#         ## We can also specify some causes that are combinations or exclusions of others\n",
    "#         if cause == 10:  ## All NON CVD (not MCI, not stroke) deaths only\n",
    "#             countThese = ((CODFlags != 1) & (CODFlags != 5))\n",
    "#             eventFlags = eventFlags * countThese\n",
    "#             return eventFlags\n",
    "#         if cause == 11:  ## All non accidental deaths only\n",
    "#             countThese = (CODFlags != 4)\n",
    "#             eventFlags = eventFlags * countThese\n",
    "#             return eventFlags\n",
    "#         if cause == 12:  ## All CVD-related deaths - including stroke\n",
    "#             countThese = ((CODFlags == 1) | (CODFlags == 5))\n",
    "#             eventFlags = eventFlags * countThese\n",
    "#             return eventFlags\n",
    "\n",
    "\n",
    "# def makeSurvObject(qMatrix, causeOfDeath):\n",
    "#     \"\"\"Take survival times and censor vector and make a survival object\"\"\"\n",
    "    \n",
    "#     ## First, get event flags from qMatrix - subjects that died have 1, those that survived have 0 in here\n",
    "#     eventFlags = getEventVec(qMatrix, causeOfDeath)\n",
    "    \n",
    "#     ## Then, get survival times (either time between exam and death (if dead) or time to end of follow up (alive)\n",
    "#     times = getSurvTime(qMatrix)\n",
    "    \n",
    "#     ## Now make a survival object (survival library)\n",
    "#     ## In Python with scikit-survival, we create structured array\n",
    "#     survObj = np.array([(bool(e), t) for e, t in zip(eventFlags, times)],\n",
    "#                       dtype=[('event', '?'), ('time', '<f8')])\n",
    "    \n",
    "#     return survObj\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def getSurvTime(qMatrix: pd.DataFrame):\n",
    "    return qMatrix[\"PERMTH_EXM\"].to_numpy()\n",
    "\n",
    "def _as_float(series):\n",
    "    # Ensure we carry NaNs (don’t coerce to int/bool too early)\n",
    "    return pd.to_numeric(series, errors=\"coerce\").to_numpy(dtype=float)\n",
    "\n",
    "def getEventVec(qMatrix: pd.DataFrame, cause: int):\n",
    "    \"\"\"\n",
    "    Return *float* array with values {0.0, 1.0, np.nan}, mirroring R behavior.\n",
    "    For cause-specific deaths, NA in UCOD_LEADING propagates: 0*NA -> NA in R.\n",
    "    \"\"\"\n",
    "    eventFlags = _as_float(qMatrix[\"MORTSTAT\"])  # may contain NaN\n",
    "\n",
    "    if cause == 0:\n",
    "        return eventFlags\n",
    "\n",
    "    CODFlags = _as_float(qMatrix[\"UCOD_LEADING\"])\n",
    "\n",
    "    def mask_equals(k):\n",
    "        # boolean mask as float {1.0, 0.0, np.nan}\n",
    "        m = (CODFlags == k)\n",
    "        m = np.where(np.isnan(CODFlags), np.nan, m.astype(float))\n",
    "        return m\n",
    "\n",
    "    def mask_not_equals(k):\n",
    "        m = (CODFlags != k)\n",
    "        m = np.where(np.isnan(CODFlags), np.nan, m.astype(float))\n",
    "        return m\n",
    "\n",
    "    if   cause == 1: countThese = mask_equals(1)\n",
    "    elif cause == 2: countThese = mask_equals(2)\n",
    "    elif cause == 3: countThese = mask_equals(3)\n",
    "    elif cause == 4: countThese = mask_equals(4)\n",
    "    elif cause == 5: countThese = mask_equals(5)\n",
    "    elif cause == 6: countThese = mask_equals(6)\n",
    "    elif cause == 7: countThese = mask_equals(7)\n",
    "    elif cause == 8: countThese = mask_equals(8)\n",
    "    elif cause == 9: countThese = mask_equals(9)\n",
    "    elif cause == 10: countThese = np.where(np.isnan(CODFlags), np.nan,\n",
    "                                            ((CODFlags != 1) & (CODFlags != 5)).astype(float))\n",
    "    elif cause == 11: countThese = mask_not_equals(4)\n",
    "    elif cause == 12: countThese = np.where(np.isnan(CODFlags), np.nan,\n",
    "                                            ((CODFlags == 1) | (CODFlags == 5)).astype(float))\n",
    "    else:\n",
    "        return eventFlags\n",
    "\n",
    "    # R does: eventFlags <- eventFlags * countThese (and 0 * NA -> NA in R!)\n",
    "    with np.errstate(invalid=\"ignore\"):\n",
    "        out = eventFlags * countThese\n",
    "    return out  # float with NaNs preserved\n",
    "\n",
    "def makeSurvObject(qMatrix: pd.DataFrame, causeOfDeath: int):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      survObj_bool: structured array for modeling (NaNs -> censored False)\n",
    "      event_raw: float array with {0.0, 1.0, np.nan} to mirror R for comparisons\n",
    "    \"\"\"\n",
    "    event_raw = getEventVec(qMatrix, causeOfDeath)       # float with NaNs kept\n",
    "    times     = getSurvTime(qMatrix).astype(float)\n",
    "\n",
    "    # modeling-friendly boolean (match common scikit-survival expectations):\n",
    "    # NA -> treat as censored False (you can change to drop if you prefer)\n",
    "    event_bool = np.where(np.isnan(event_raw), False, event_raw.astype(bool))\n",
    "\n",
    "    survObj_bool = np.array(list(zip(event_bool, times)),\n",
    "                            dtype=[('event', '?'), ('time', '<f8')])\n",
    "\n",
    "    return survObj_bool\n",
    "\n",
    "\n",
    "\n",
    "def calcBioAge(coxModelNew, nullModel, dataTable):\n",
    "    \"\"\"This will take the coxModel plus the input data table (covariates used for the cox model)\n",
    "    it will then loop over the data table and calculate the delta ages for each individual\n",
    "    The cox model assumes that the hazard function hi(t) for each subject i\n",
    "    can be broken down into log additive terms according to the linear (lm) model\n",
    "    plus the universal time-dependent (follow up time) term  h0(t)\n",
    "    e.g. here: hi(t) = h0(t)*exp(beta1*startAge + beta2*x2 + beta3*x3 + beta4*x4)\"\"\"\n",
    "    \n",
    "    ## First extract maximum likelihood betas from full coxModel\n",
    "    betasCOX = coxModelNew.coef_\n",
    "    betasNull = nullModel.coef_\n",
    "    \n",
    "    ## We know that h is the mortality function according to gompertz - we can infer that:\n",
    "    ##     beta1*ageStart == ln(2)/MRDT*ageStart\n",
    "    ## <=> beta1 == ln(2)/MRDT\n",
    "    ## <=> MRDT == ln(2)/beta1\n",
    "    ##\n",
    "    betaOne = betasNull[0]\n",
    "    MRDTfit = round(np.log(2) / betaOne, 2)\n",
    "    \n",
    "    riskMod = coxModelNew.predict(dataTable)\n",
    "    riskNull = nullModel.predict(dataTable[[\"chronAge\"]])\n",
    "    \n",
    "    logRiskRatio = np.log(riskMod / riskNull)\n",
    "    ageBioDelta = logRiskRatio / np.log(2) * MRDTfit\n",
    "    return ageBioDelta\n",
    "\n",
    "\n",
    "def drawScree(fileName, svCutP, svCut, screeDat):\n",
    "    \"\"\"Draw scree plot (pdf)\"\"\"\n",
    "    \n",
    "    print(f\"> Writing out scree plot: [{fileName}] ... \", end=\"\")\n",
    "    plt.figure()\n",
    "    words = f\"Scree Plot \\n Cutoff: {svCutP}% (blue line) at PC{svCut} (red line)\"\n",
    "    plt.plot(screeDat * 100, color='gray', linewidth=2)\n",
    "    plt.scatter(range(len(screeDat)), screeDat * 100, c='black', marker='o')\n",
    "    plt.axvline(x=svCut, linewidth=2, linestyle='--', color='red')\n",
    "    plt.axhline(y=screeDat[svCut] * 100, linestyle='--', linewidth=2, color='blue')\n",
    "    plt.xlabel(\"PC Nr.\")\n",
    "    plt.ylabel(\"Variance explained (%)\")\n",
    "    plt.title(words)\n",
    "    plt.savefig(fileName)\n",
    "    plt.close()\n",
    "    print(\"Done\")\n",
    "\n",
    "\n",
    "def userDataOut():\n",
    "    \"\"\"Function to return linAge2 and individual PCs for user supplied data - just a data dump ...\"\"\"\n",
    "    \n",
    "    pcFoldVsYoung = 1  ## Convert PC coordinates into Z-changes vs NHANES young controls\n",
    "    dropSanity = 1  ## Remove NHANES sanity check SEQs before returning user data matrix\n",
    "    \n",
    "    ## 1) Append chronAge, bioAge, sex, deltaBioAge and sex-specific PCs to user data matrix\n",
    "    chronAge = np.round(coxCovs_user.values[:, 0] / 12, 2)\n",
    "    linAge2 = np.round(bioAge_user / 12, 2)\n",
    "    bioAge_del = np.round(linAge2 - chronAge, 2)\n",
    "    dataMat_user_temp = pd.DataFrame(dataMat_user)\n",
    "    dataMat_user_temp['chronAge'] = chronAge\n",
    "    dataMat_user_temp['linAge2'] = linAge2\n",
    "    dataMat_user_temp['bioAge_del'] = bioAge_del\n",
    "    \n",
    "    ## 2) Sanity check - check that linAge2 values for reference samples are correct\n",
    "    sanSam = dataMat_user_temp[\"SEQN\"] > 100000  ## ID sanity samples in training set\n",
    "    sanSEQs = dataMat_user_temp.loc[sanSam, \"SEQN\"] - 100000\n",
    "    refSEQs = demoTrain[\"SEQN\"].values  ## Get SEQs of sanity samples\n",
    "    refPos = np.where(np.isin(refSEQs, sanSEQs))[0]  ## Match sanity sample to training data\n",
    "    sanVals = linAge2[sanSam]  ## Get linAge2 for sanity samples from sanity run\n",
    "    refVals = (bioAge_train / 12)[refPos]  ## Get linAge2 for same samples from training data\n",
    "    corCof = round(np.corrcoef(refVals, sanVals)[0, 1], 4)  ## These should be the same (correlation of 1)\n",
    "    \n",
    "    if corCof != 1:\n",
    "        print(\" > Sanity check failed \")\n",
    "        return 0\n",
    "    else:\n",
    "        print(\" > Sanity check passed \")\n",
    "    \n",
    "    ## 3) Normalize PCs of user SEQs to those of young reference set from NHANES\n",
    "    nPCs = pcDatMat.shape[1]  ## Use only PCs that have not been dropped by dimensionality reduction\n",
    "    nPCs_used = len(coxModelM.coef_)\n",
    "    \n",
    "    ## Normalize by training set (00/99) only\n",
    "    seqSel = qDataMat[\"yearsNHANES\"] == 9900\n",
    "\n",
    "    ## Select age cutoff\n",
    "    ageVec = qDataMat[\"RIDAGEYR\"]\n",
    "    ageSel = ageVec <= 50\n",
    "    ## Select male/female separately\n",
    "    pcSex_sel = qDataMat[\"RIAGENDR\"] == 1\n",
    "    \n",
    "    ## Combine selections - all in reference data only\n",
    "    selVec_M = ageSel & seqSel & pcSex_sel\n",
    "    selVec_F = ageSel & seqSel & ~pcSex_sel\n",
    "    \n",
    "    ## Extract data matrix\n",
    "    pcMat_temp_M = pcDatMat[selVec_M]\n",
    "    pcMat_temp_F = pcDatMat[selVec_F]\n",
    "    \n",
    "    ## Get mean PCs for male and females\n",
    "    meanPCs_M = pcMat_temp_M.mean(axis=0)\n",
    "    meanPCs_F = pcMat_temp_F.mean(axis=0)\n",
    "    sdPCs_M = pcMat_temp_M.std(axis=0)\n",
    "    sdPCs_F = pcMat_temp_F.std(axis=0)\n",
    "    \n",
    "    ## Select PCs from pcMatrix, normalise by mean of PC for sex\n",
    "    sexSel = coxCovs_user.values[:, -1]\n",
    "    \n",
    "    ## Get Male PCs\n",
    "    PCs_M = coxCovs_user.values[sexSel == 1, 1:(nPCs + 1)]\n",
    "    ## Get Female PCs\n",
    "    PCs_F = coxCovs_user.values[sexSel == 2, 1:(nPCs + 1)]\n",
    "    \n",
    "    if pcFoldVsYoung == 1:\n",
    "        ## Normalize PCs by mean of NHANES young controls - separately for male and female SEQs\n",
    "        ## Now turn user data PCs into Z-scores relative to training data\n",
    "        PCs_M = PCs_M - meanPCs_M.values  ## Subtract mean from columns\n",
    "        PCs_M = PCs_M @ np.diag(1 / sdPCs_M.values)\n",
    "        PCs_F = PCs_F - meanPCs_F.values  ## Subtract mean from columns\n",
    "        PCs_F = PCs_F @ np.diag(1 / sdPCs_F.values)\n",
    "    \n",
    "    ## 4) Filter PC data for male/female SEQs and drop non-model PCs\n",
    "    formula_M = str(formM)\n",
    "    formula_F = str(formF)\n",
    "    \n",
    "    ## Make masks - 1 if used, 0 if not included - for male and female PCs\n",
    "    ## Males\n",
    "    mask_M = np.zeros(nPCs)\n",
    "    for token in range(1, nPCs_used):\n",
    "        pcNr = int(formula_M.split(\"+ PC\")[token].split(\"+ \")[0])-1\n",
    "        mask_M[pcNr] = 1\n",
    "    \n",
    "    ## Females\n",
    "    nPCs_used = len(coxModelF.coef_)\n",
    "    mask_F = np.zeros(nPCs)\n",
    "    for token in range(1, nPCs_used):\n",
    "        pcNr = int(formula_F.split(\"+ PC\")[token].split(\"+ \")[0])-1\n",
    "        mask_F[pcNr] = 1\n",
    "    \n",
    "    ## Now drop any PCs not actually used in the model\n",
    "    PCs_M = PCs_M[:, mask_M == 1]\n",
    "    PCs_F = PCs_F[:, mask_F == 1]\n",
    "    \n",
    "    ## 5) Make one data matrix combining original parameters, sex-specific PCs used by clock and LinAge2 results\n",
    "    ## Make combined column names\n",
    "    mPCs = [f\"{col}M\" for col in pcDatMat.columns[mask_M == 1]]\n",
    "    fPCs = [f\"{col}F\" for col in pcDatMat.columns[mask_F == 1]]\n",
    "    allCols = list(dataMat_user_temp.columns) + mPCs + fPCs\n",
    "    \n",
    "    ## Add NA PCsM for females and NA PCsF for males\n",
    "    PCs_M_merge = np.hstack([PCs_M, np.full((PCs_M.shape[0], PCs_F.shape[1]), np.nan)])\n",
    "    PCs_F_merge = np.hstack([np.full((PCs_F.shape[0], PCs_M.shape[1]), np.nan), PCs_F])\n",
    "    \n",
    "    ## Combine PCs with with parameters from dataMat\n",
    "    outMat_M = np.hstack([dataMat_user_temp[sexSel == 1].values, PCs_M_merge])\n",
    "    outMat_F = np.hstack([dataMat_user_temp[sexSel == 2].values, PCs_F_merge])\n",
    "    \n",
    "    ## Combine male and female SEQs\n",
    "    nSEQs = len(sexSel)\n",
    "    mParas = len(allCols)\n",
    "    outMat = np.zeros((nSEQs, mParas))\n",
    "    outMat[sexSel == 1, :mParas] = outMat_M[:, :mParas]\n",
    "    outMat[sexSel == 2, :mParas] = outMat_F[:, :mParas]\n",
    "    \n",
    "    ## 5) Remove sanity data from user data matrix\n",
    "    maxSEQ = 100000  ## SEQs over 10,000 are sanity data, added to user data to check\n",
    "    allSEQs = dataMat_user_temp[\"SEQN\"].values\n",
    "    keep = allSEQs < maxSEQ\n",
    "    if dropSanity == 1:\n",
    "        outMat = outMat[keep, :]\n",
    "    \n",
    "    return pd.DataFrame(outMat, columns=allCols)\n",
    "\n",
    "\n",
    "def plotBars(outMat_user, userSEQ):\n",
    "    \"\"\"Turn individual SEQs of user out matrix into bar graph\"\"\"\n",
    "    \n",
    "    ## First, get sex of SEQ of interest\n",
    "    rowN = np.where(outMat_user[\"SEQN\"] == userSEQ)[0][0]\n",
    "    userSex = (int(not pd.isna(outMat_user.loc[rowN, \"PC1M\"])) * 1 +\n",
    "              2 * int(not pd.isna(outMat_user.loc[rowN, \"PC1F\"])))\n",
    "    \n",
    "    ## Get boundaries for male and female PCs\n",
    "    femPCstart = outMat_user.columns.get_loc(\"PC1F\")\n",
    "    malPCstart = outMat_user.columns.get_loc(\"PC1M\")\n",
    "    endPCs = outMat_user.shape[1]\n",
    "    \n",
    "    ## Get PC values\n",
    "    if userSex == 1:  ## For male SEQ, get male PCs\n",
    "        pcVals = outMat_user.iloc[rowN, malPCstart:(femPCstart - 1)].values  ## Model PCs\n",
    "        names = [\"01_PC1M\", \"02_PC2M\", \"03_PC5M\", \"04_PC6M\", \"05_PC8M\", \"06_PC11M\", \"07_PC15M\",\n",
    "                \"08_PC16M\", \"09_PC17M\", \"10_PC19M\", \"11_PC24M\", \"12_PC25M\", \"13_PC27M\",\n",
    "                \"14_PC31M\", \"15_PC33M\", \"16_PC36M\", \"17_PC42M\"]\n",
    "    \n",
    "    if userSex == 2:  ## For female SEQ, get female PCs\n",
    "        pcVals = outMat_user.iloc[rowN, femPCstart:endPCs].values\n",
    "        names = [\"01_PC1F\", \"02_PC2F\", \"03_PC4F\", \"04_PC6F\", \"05_PC11F\", \"06_PC13F\", \"07_PC20F\",\n",
    "                \"08_PC22F\", \"09_PC23F\", \"10_PC24F\", \"11_PC28F\", \"12_PC31F\", \"13_PC32F\",\n",
    "                \"14_PC32F\", \"15_PC35F\", \"16_PC38F\", \"17_PC39F\"]\n",
    "    \n",
    "    barObj = pd.DataFrame({'names': names, 'pcVals': pcVals})\n",
    "    \n",
    "    ## Plot bar graph\n",
    "    barObj['pcVals'] = np.round(barObj['pcVals'].astype(float), 2)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    bars = ax.bar(barObj['names'], barObj['pcVals'], color='lightgrey', width=0.8)\n",
    "    \n",
    "    for i, (name, val) in enumerate(zip(barObj['names'], barObj['pcVals'])):\n",
    "        ax.text(i, val, str(val), ha='center', va='bottom', size=7)\n",
    "    \n",
    "    ax.set_ylabel('PC values', fontsize=7, fontfamily='Arial')\n",
    "    ax.set_ylim(-5, 5)\n",
    "    ax.set_yticks(np.arange(-5, 5.5, 0.5))\n",
    "    ax.tick_params(axis='both', labelsize=7)\n",
    "    plt.xticks(rotation=15, fontfamily='Arial')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "1e79880a-4248-4cb3-bbc9-9482231d5ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I) Reading data and configuration files\n",
      "#######################################\n",
      "> Reading parameter file: [paraInit.csv] ... Done\n"
     ]
    }
   ],
   "source": [
    "#####################################################################################################################\n",
    "####                                     >>> MAIN CUSTOM CLOCK SCRIPT <<<                                        ####\n",
    "#####################################################################################################################\n",
    "## Get source file name and report start\n",
    "\n",
    "###################################\n",
    "## I) DATA FILES AND DATA IMPORT ##\n",
    "###################################\n",
    "\n",
    "## NOTE ON REDUCED FEATURE SET:\n",
    "## We dropped the following features from the codebook:\n",
    "## 1) Fibrinogen\n",
    "## 2) Gamma Glutamyl Transferase (GGT)\n",
    "\n",
    "## We are also dropping the following features from the data matrix after they have been used to calculate LDL (below)\n",
    "## 1) Total Cholesterol\n",
    "## 2) Triglycerides\n",
    "## 3) HDL\n",
    "\n",
    "print(\"\\nI) Reading data and configuration files\")\n",
    "print(\"#######################################\")\n",
    "\n",
    "## First, read parameter file. This file contains some parameters that can be changed.\n",
    "paraFile = \"paraInit.csv\"\n",
    "print(f\"> Reading parameter file: [{paraFile}] ... \", end=\"\")\n",
    "paras = pd.read_csv(paraFile, sep=\",\", header=0)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "c9e0ad36-d681-4f19-911f-4e79b273dfe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rowNr</th>\n",
       "      <th>pName</th>\n",
       "      <th>pValue</th>\n",
       "      <th>Explanation</th>\n",
       "      <th>varName</th>\n",
       "      <th>NOTE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>errorLevel</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Set error level – in % of para value (normally...</td>\n",
       "      <td>errLevl</td>\n",
       "      <td>This will only affect noise level of custom cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NAcutOffpercent</td>\n",
       "      <td>0.09</td>\n",
       "      <td>Cut off percentage for NAs. Columns with more ...</td>\n",
       "      <td>pNAcut</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>PCcutOffpercent</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Cut off percentage for PC based on variance ex...</td>\n",
       "      <td>svCutP</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>lowerAgeLimit</td>\n",
       "      <td>40.00</td>\n",
       "      <td>Lower age bracket of cohort</td>\n",
       "      <td>ageLower</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>upperAgeLimit</td>\n",
       "      <td>84.00</td>\n",
       "      <td>Upper age bracket of cohort</td>\n",
       "      <td>ageUpper</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>derivedFeatFlag</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Set to zero (0) to skip calculating derived fe...</td>\n",
       "      <td>useDerived</td>\n",
       "      <td>Will only calculate derived features if the re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rowNr            pName  pValue  \\\n",
       "0      1       errorLevel    0.10   \n",
       "1      2  NAcutOffpercent    0.09   \n",
       "2      3  PCcutOffpercent    0.50   \n",
       "3      4    lowerAgeLimit   40.00   \n",
       "4      5    upperAgeLimit   84.00   \n",
       "5      6  derivedFeatFlag    1.00   \n",
       "\n",
       "                                         Explanation     varName  \\\n",
       "0  Set error level – in % of para value (normally...     errLevl   \n",
       "1  Cut off percentage for NAs. Columns with more ...      pNAcut   \n",
       "2  Cut off percentage for PC based on variance ex...      svCutP   \n",
       "3                        Lower age bracket of cohort    ageLower   \n",
       "4                        Upper age bracket of cohort    ageUpper   \n",
       "5  Set to zero (0) to skip calculating derived fe...  useDerived   \n",
       "\n",
       "                                                NOTE  \n",
       "0  This will only affect noise level of custom cl...  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  \n",
       "5  Will only calculate derived features if the re...  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c409eb9f-dc2a-4f73-be4d-b67fdc90c624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Reading parameters ... \n",
      "   errLevl: 0.1\n",
      "   NAcut: 0.09\n",
      "   Age limits: [40.0, 84.0]\n",
      "   Use Derived Features: 1.0  ... Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Now use this to fix some important parameters\n",
    "## See paraInit.csv for summary of what these mean\n",
    "print(\"> Reading parameters ... \")\n",
    "errLevl = paras.loc[paras[\"pName\"] == \"errorLevel\", \"pValue\"].values[0]\n",
    "print(f\"   errLevl: {errLevl}\")\n",
    "pNAcut = paras.loc[paras[\"pName\"] == \"NAcutOffpercent\", \"pValue\"].values[0]\n",
    "print(f\"   NAcut: {pNAcut}\")\n",
    "svCutP = paras.loc[paras[\"pName\"] == \"PCcutOffpercent\", \"pValue\"].values[0]\n",
    "ageLower = paras.loc[paras[\"pName\"] == \"lowerAgeLimit\", \"pValue\"].values[0]\n",
    "ageUpper = paras.loc[paras[\"pName\"] == \"upperAgeLimit\", \"pValue\"].values[0]\n",
    "print(f\"   Age limits: [{ageLower}, {ageUpper}]\")\n",
    "useDerived = paras.loc[paras[\"pName\"] == \"derivedFeatFlag\", \"pValue\"].values[0]\n",
    "print(f\"   Use Derived Features: {useDerived}  ... \", end=\"\")\n",
    "verbose = 0  ## Sets level of verbosity for some functions - 0 means not very\n",
    "print(\"Done\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "9dce1552-b939-46d0-a74a-7a36e3988a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Reading NHANES training data file: [mergedDataNHANES9902.csv] ... Done\n"
     ]
    }
   ],
   "source": [
    "## Second, read in csv of total NHANES (continuous) data - here we load the year 1999 with most\n",
    "## lab data included\n",
    "dataFileName = \"mergedDataNHANES9902.csv\"\n",
    "print(f\"> Reading NHANES training data file: [{dataFileName}] ... \", end=\"\")\n",
    "masterData = pd.read_csv(dataFileName)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "4b8ffe9e-906b-46ab-b042-e99a08d8b365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Reading codebook file: [codebook_linAge2.csv] ... Done\n"
     ]
    }
   ],
   "source": [
    "## Codebook file\n",
    "codeBookFile = \"codebook_linAge2.csv\"\n",
    "print(f\"> Reading codebook file: [{codeBookFile}] ... \", end=\"\")\n",
    "codeBook = pd.read_csv(codeBookFile)\n",
    "print(\"Done\")\n",
    "## The codebook file contains the Variable names in NHANES 99/00 format (Var) and human readable (Human)\n",
    "## The codebook file  also contains a flag (Demo/Exam...) coding for the type of data - the flags are:\n",
    "##     DEMO: Demographic data\n",
    "##     Q        : Questionnaire\n",
    "##     E        : Medical Examination\n",
    "##     LAB      : Clinical Laboratory\n",
    "##     MORTALITY: Mortality / Survival and cause of death linkage\n",
    "## Finally, the codebook contains a flag indicating  numerical data (Data) and forced inclusion (ForceInc)\n",
    "## These flags can be 1 (yes) or 0 (no)\n",
    "## Set both Data and ForceInc to 1 for variables to be used for custom clock..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "cb4e7751-a8a0-4f1e-bc3d-9a1b9a55971c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var</th>\n",
       "      <th>Human</th>\n",
       "      <th>Demo/Exam/Quest/Lab/Mort</th>\n",
       "      <th>Data</th>\n",
       "      <th>ForceInc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEQN</td>\n",
       "      <td>Patient number</td>\n",
       "      <td>DEMO</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SDDSRVYR</td>\n",
       "      <td>Data release cycle</td>\n",
       "      <td>DEMO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RIDSTATR</td>\n",
       "      <td>Interview/Examination status</td>\n",
       "      <td>DEMO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RIDEXMON</td>\n",
       "      <td>6 month time period when exam was performed</td>\n",
       "      <td>DEMO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RIAGENDR</td>\n",
       "      <td>Gender</td>\n",
       "      <td>DEMO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>LBDSCRSI</td>\n",
       "      <td>Creatinine (umol/L)</td>\n",
       "      <td>LAB</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>LBXSNASI</td>\n",
       "      <td>Sodium (mmol/L)</td>\n",
       "      <td>LAB</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>LBXSKSI</td>\n",
       "      <td>Potassium (mmol/L)</td>\n",
       "      <td>LAB</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>LBXSCLSI</td>\n",
       "      <td>Chloride (mmol/L)</td>\n",
       "      <td>LAB</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>LBDSGBSI</td>\n",
       "      <td>Globulin (g/L)</td>\n",
       "      <td>LAB</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1144 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Var                                        Human  \\\n",
       "0         SEQN                               Patient number   \n",
       "1     SDDSRVYR                           Data release cycle   \n",
       "2     RIDSTATR                 Interview/Examination status   \n",
       "3     RIDEXMON  6 month time period when exam was performed   \n",
       "4     RIAGENDR                                       Gender   \n",
       "...        ...                                          ...   \n",
       "1139  LBDSCRSI                          Creatinine (umol/L)   \n",
       "1140  LBXSNASI                              Sodium (mmol/L)   \n",
       "1141   LBXSKSI                           Potassium (mmol/L)   \n",
       "1142  LBXSCLSI                            Chloride (mmol/L)   \n",
       "1143  LBDSGBSI                               Globulin (g/L)   \n",
       "\n",
       "     Demo/Exam/Quest/Lab/Mort  Data  ForceInc  \n",
       "0                        DEMO     1         1  \n",
       "1                        DEMO     0         0  \n",
       "2                        DEMO     0         0  \n",
       "3                        DEMO     0         0  \n",
       "4                        DEMO     0         0  \n",
       "...                       ...   ...       ...  \n",
       "1139                      LAB     1         1  \n",
       "1140                      LAB     1         1  \n",
       "1141                      LAB     1         1  \n",
       "1142                      LAB     1         1  \n",
       "1143                      LAB     1         1  \n",
       "\n",
       "[1144 rows x 5 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeBook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "0b8db87a-7b12-4159-b8db-78203b4f9464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Reading user data file: [userData.csv]... Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Read in user data, append to sanity data set and run through whole script in parallel to NHANES test data\n",
    "sanityDataFile = \"userData_sanity.csv\"\n",
    "userDataFile = \"userData.csv\"\n",
    "print(f\"> Reading user data file: [{userDataFile}]... \", end=\"\")\n",
    "userDataMat = pd.read_csv(userDataFile)\n",
    "sanityData = pd.read_csv(sanityDataFile)\n",
    "print(\"Done\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "96dee74f-ad58-4e2f-be5d-9357af1d8ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Digitizing cotinine data ... Done\n",
      "\n",
      "> Digitizing cotinine data ... Done\n",
      "\n",
      "> Digitizing cotinine data ... Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Digitize continine to turn into smoking intensity\n",
    "masterData = digiCot(masterData)\n",
    "sanityData = digiCot(sanityData)\n",
    "## Only do this for user data if not already done by user\n",
    "#digiCotFlag = input(\"Have you entered cotinine values (C) or smoking status (S) ? > \")\n",
    "digiCotFlag = \"C\"\n",
    "if digiCotFlag == \"C\" or digiCotFlag == \"c\":\n",
    "    userDataMat = digiCot(userDataMat)\n",
    "\n",
    "## Now bind sanity data to usder data\n",
    "userDataMat = pd.concat([userDataMat, sanityData], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a1dccc86-7963-4a78-87b6-85b3aa9a2d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "II) Selecting and cleaning data\n",
      "###############################\n",
      "> Splitting data matrix ...  selecting data ...   selecting qData ... Done\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "## II)  PREPARE DATA MATRIX ##\n",
    "##############################\n",
    "\n",
    "###############################\n",
    "## II.i) FILTER INPUT MATRIX ##\n",
    "###############################\n",
    "print(\"\\nII) Selecting and cleaning data\")\n",
    "print(\"###############################\")\n",
    "\n",
    "print(\"> Splitting data matrix ... \", end=\"\")\n",
    "## Drop non-data columns from master data based on include flags in the codebook\n",
    "print(\" selecting data ...  \", end=\"\")\n",
    "incList = markIncsFromCodeBook(codeBook)\n",
    "dataMat = dropCols(masterData, incList)  ## Main data matrix for clock\n",
    "dataMat_user = dropCols(userDataMat, incList)  ## User data matrix for clock\n",
    "\n",
    "## Now we make a questionnaire Data matrix - everything OTHER than the numerical / clinical data\n",
    "## qDataMat will include anything that is NOT flagged as \"data\" in the codebook\n",
    "print(\" selecting qData ... \", end=\"\")\n",
    "qDataMat = qDataMatGen(masterData, incList)  ## NOTE: This is pretty much the same as dropCols for dataMatrix ...\n",
    "qDataMat_user = qDataMatGen(userDataMat, incList)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e2592209-e4f4-4fee-9a49-7e96b983fbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    17472.000000\n",
       "mean        24.794676\n",
       "std          7.034929\n",
       "min          7.990000\n",
       "25%         19.500000\n",
       "50%         24.100000\n",
       "75%         28.890000\n",
       "max         66.440000\n",
       "Name: BMXBMI, dtype: float64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataMat['BMXBMI'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "646223c1-759f-4db6-abce-a1625359056a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 columns of masterData:\n",
      "['Unnamed: 0', 'yearsNHANES', 'SEQN', 'RIAGENDR', 'RIDAGEYR']\n",
      "\n",
      "Is 'yearsNHANES' in masterData? True\n",
      "Index of yearsNHANES: 1\n"
     ]
    }
   ],
   "source": [
    "# What's in the first few columns?\n",
    "print(\"First 5 columns of masterData:\")\n",
    "print(masterData.columns[:5].tolist())\n",
    "print(\"\\nIs 'yearsNHANES' in masterData?\", 'yearsNHANES' in masterData.columns)\n",
    "print(\"Index of yearsNHANES:\", masterData.columns.get_loc('yearsNHANES') if 'yearsNHANES' in masterData.columns else \"NOT FOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "140f714d-c187-4b6b-b418-943fb537e9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Populating derived features ...  fs scores ... LDLV ... Albumin Creatinine ratio ... Done\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "## II.ii) POPULATE DERIVED FEATURES ##\n",
    "######################################\n",
    "## Only gets done if useDerived == 1, skipped else\n",
    "if useDerived:\n",
    "    print(\"> Populating derived features ... \", end=\"\")\n",
    "    print(\" fs scores ...\", end=\"\")\n",
    "    \n",
    "    ######### FS scores\n",
    "    ## NHANES DATA\n",
    "    fs1Score = popPCFIfs1(qDataMat)\n",
    "    fs2Score = popPCFIfs2(qDataMat)\n",
    "    fs3Score = popPCFIfs3(qDataMat)\n",
    "    dataMat['fs1Score'] = fs1Score\n",
    "    dataMat['fs2Score'] = fs2Score\n",
    "    dataMat['fs3Score'] = fs3Score\n",
    "    \n",
    "    ## USER DATA\n",
    "    fs1Score = popPCFIfs1(qDataMat_user)\n",
    "    fs2Score = popPCFIfs2(qDataMat_user)\n",
    "    fs3Score = popPCFIfs3(qDataMat_user)\n",
    "    dataMat_user['fs1Score'] = fs1Score\n",
    "    dataMat_user['fs2Score'] = fs2Score\n",
    "    dataMat_user['fs3Score'] = fs3Score\n",
    "    \n",
    "    ######### LDL scores\n",
    "    ## LDL values\n",
    "    print(\" LDLV ...\", end=\"\")\n",
    "    LDLV = populateLDL(dataMat, qDataMat)\n",
    "    dataMat['LDLV'] = LDLV\n",
    "    \n",
    "    ## USER DATA\n",
    "    LDLV = populateLDL(dataMat_user, qDataMat_user)\n",
    "    dataMat_user['LDLV'] = LDLV\n",
    "    \n",
    "    ######### Urine albumin to creatinine ratio\n",
    "    ## Urine Albumin Creatinine ratio\n",
    "    print(\" Albumin Creatinine ratio ... \", end=\"\")\n",
    "    creaVals = dataMat[\"URXUCRSI\"].values\n",
    "    albuVals = dataMat[\"URXUMASI\"].values\n",
    "    crAlbRat = albuVals / (creaVals * 1.1312 * 10**-4)\n",
    "    dataMat['crAlbRat'] = crAlbRat\n",
    "    \n",
    "    ## USER DATA\n",
    "    creaVals = dataMat_user[\"URXUCRSI\"].values\n",
    "    albuVals = dataMat_user[\"URXUMASI\"].values\n",
    "    crAlbRat = albuVals / (creaVals * 1.1312 * 10**-4)\n",
    "    dataMat_user['crAlbRat'] = crAlbRat\n",
    "    \n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ccb48364-17cb-4e56-96ae-1d07e423f2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now drop all columns no longer needed - because paras were used to derive features ## \n",
    "### What is this abomination of dropping?\n",
    "# drop = dataMat.columns.get_loc(\"LBDHDLSI\")\n",
    "# dataMat = dataMat.drop(dataMat.columns[drop], axis=1)\n",
    "# dataMat_user = dataMat_user.drop(dataMat_user.columns[drop], axis=1)\n",
    "\n",
    "# drop = dataMat.columns.get_loc(\"LBDSTRSI\")\n",
    "# dataMat = dataMat.drop(dataMat.columns[drop], axis=1)\n",
    "# dataMat_user = dataMat_user.drop(dataMat_user.columns[drop], axis=1)\n",
    "\n",
    "# drop = dataMat.columns.get_loc(\"LBDTCSI\")\n",
    "# dataMat = dataMat.drop(dataMat.columns[drop], axis=1)\n",
    "#dataMat_user = dataMat_user.drop(dataMat_user.columns[drop], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "d6fe8bff-40af-4780-bbc9-8b2025d6a7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Removing subjects with missing age data ... Done \n"
     ]
    }
   ],
   "source": [
    "## We also need to drop all subjects for which we have no information on age\n",
    "print(\"> Removing subjects with missing age data ... \", end=\"\")\n",
    "subSansAge = qDataMat[\"RIDAGEEX\"].isna()\n",
    "dataMat = dataMat[~subSansAge].reset_index(drop=True)\n",
    "qDataMat = qDataMat[~subSansAge].reset_index(drop=True)\n",
    "print(\"Done \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "f5754418-37eb-4d1d-b323-b59ec11e2fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Removing accidental deaths ... Done\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "## II.iii) REFINE COHORT BY FURTHER DEMOGRAPHIC AND LAB CRITERIA  ##\n",
    "####################################################################\n",
    "## Drop all accidental death cases\n",
    "print(\"> Removing accidental deaths ... \", end=\"\")\n",
    "keepRows = nonAccidDeathFlags(qDataMat)\n",
    "dataMat = dataMat[keepRows].reset_index(drop=True)\n",
    "qDataMat = qDataMat[keepRows].reset_index(drop=True)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "28420a61-e583-4b21-9586-5a402fdaa9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19347, 63), (19347, 34))"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataMat.shape, qDataMat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "32dbbf5c-f55e-483e-9e48-ee4ae17c5881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Applying age filter: [40.0, 84.0] years  ... Done\n"
     ]
    }
   ],
   "source": [
    "## Remove individuals below the age of ageCut - also remove individuals over 84\n",
    "## as the age data is top-coded at 84 (e.g. 100 is recorded as 85)\n",
    "print(f\"> Applying age filter: [{ageLower}, {ageUpper}] years  ... \", end=\"\")\n",
    "keepRows = selectAgeBracket(qDataMat, ageLower, ageUpper)\n",
    "dataMat = dataMat[keepRows].reset_index(drop=True)\n",
    "## NOTE: Any time that we drop rows (subject), we have to also drop the same rows\n",
    "## from demographic data and update the sequence data:\n",
    "qDataMat = qDataMat[keepRows].reset_index(drop=True)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "cadf3fd2-2942-4094-b269-fd46d0a25d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5700, 63), (5700, 34))"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataMat.shape, qDataMat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "86749d02-c5e7-4cfb-8f35-4264d5b6a896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> NA percentage threshold for dropping feature is set to: 9.0%\n",
      "> Dropping features with more NAs than threshold ... Done\n"
     ]
    }
   ],
   "source": [
    "## Next, we need to remove columns (features) with excessive number of missing values\n",
    "print(f\"> NA percentage threshold for dropping feature is set to: {pNAcut*100}%\")\n",
    "print(\"> Dropping features with more NAs than threshold ... \", end=\"\")\n",
    "dataMat = dropNAcolumns(dataMat, pNAcut, 1, verbose)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "83f8bb7a-a20f-4b28-93f7-001347e25157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5700, 63), (5700, 34))"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataMat.shape, qDataMat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "3d732e70-b8e6-422d-9eb2-0bc3b89cfe9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Dropping subjects with NAs  ... Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"> Dropping subjects with NAs  ... \", end=\"\")\n",
    "## Drop all subjects with missing values from the dataset\n",
    "keepRows = getNonNARows(dataMat)\n",
    "dataMat = dataMat[keepRows].reset_index(drop=True)\n",
    "## Also need to again update the demographic matrix to remove the same people\n",
    "qDataMat = qDataMat[keepRows].reset_index(drop=True)\n",
    "print(\"Done\\n\")\n",
    "\n",
    "dataMat.drop([\"LBDHDLSI\", \"LBDSTRSI\", \"LBDTCSI\"], axis=1, inplace=True)\n",
    "dataMat_user.drop([\"LBDHDLSI\", \"LBDSTRSI\", \"LBDTCSI\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "f639cb03-363e-4ef8-a4a2-8af13198e103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4423, 60), (4423, 34))"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataMat.shape, qDataMat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "04da2a8c-ece0-4a3c-9d31-2bdc4e77596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('keepRows_R.json', 'r') as f:\n",
    "    keepRows_R = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ef6e5ef-6934-424d-9d90-599cc6a4b9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.array(keepRows_R)!=keepRows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcd8e404-ede2-4c2e-a76e-e81fdd6badf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "III) Normalization and parameter transformation \n",
      "#################################################\n",
      "> Loading transformation options for distributions - log transforms or not onlyDone\n",
      "> Applying transformations:\n",
      "> Applying boxCox transformed  ... Done\n",
      "> Applying boxCox transformed  ... Done\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "## III) NORMALIZATION  ##\n",
    "#########################\n",
    "print(\"\\nIII) Normalization and parameter transformation \")\n",
    "print(\"#################################################\")\n",
    "\n",
    "## Box-cox / log transforms of specfic features here ##\n",
    "print(\"> Loading transformation options for distributions - log transforms or not only\", end=\"\")\n",
    "boxCox_lam = pd.read_csv(\"logNoLog.csv\").iloc[1:2, :]\n",
    "print(\"Done\")\n",
    "\n",
    "print(\"> Applying transformations:\")\n",
    "## Loop over all data items, look up appropriate transformation, then apply that\n",
    "dataMat_trans = boxCoxTransform(boxCox_lam, dataMat)\n",
    "dataMat_trans_user = boxCoxTransform(boxCox_lam, dataMat_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0976cecb-d97f-4c7a-af6a-355a076d4662",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMat_trans_user_R = pd.read_csv('dataMat_trans_userR.csv')\n",
    "dataMat_trans_R = pd.read_csv('dataMat_trans_R.csv')\n",
    "\n",
    "dataMat_user_R = pd.read_csv('dataMat_userR.csv')\n",
    "dataMat_R = pd.read_csv('dataMat_R.csv')\n",
    "\n",
    "qDataMat_user_R = pd.read_csv('qDataMat_user_R.csv')\n",
    "qDataMat_R = pd.read_csv('qDataMat_R.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "657cb213-bac0-405f-bfc1-d020dc994b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.testing.assert_frame_equal(dataMat, dataMat_R, check_dtype=False)\n",
    "pd.testing.assert_frame_equal(dataMat_user, dataMat_user_R, check_dtype=False)\n",
    "\n",
    "pd.testing.assert_frame_equal(qDataMat, qDataMat_R, check_dtype=False)\n",
    "pd.testing.assert_frame_equal(qDataMat_user, qDataMat_user_R, check_dtype=False)\n",
    "\n",
    "pd.testing.assert_frame_equal(dataMat_trans, dataMat_trans_R, check_dtype=False)\n",
    "pd.testing.assert_frame_equal(dataMat_trans_user, dataMat_trans_user_R, check_dtype=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d22645a-31cf-4a4a-8c64-ec75d3316383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Normalizing as z-score  ... by 9900 cohort young individuals ... Done\n"
     ]
    }
   ],
   "source": [
    "############## Turn parameter values into Z-scores #########################\n",
    "############################################################################\n",
    "## PICK NORMALIZATION OPTION HERE BY CALLING FUNCTION\n",
    "print(\"> Normalizing as z-score  ... by 9900 cohort young individuals ... \", end=\"\")\n",
    "dataMatNorm = normAsZscores_99_young_mf(dataMat_trans, qDataMat, dataMat_trans, qDataMat)  ## Male Female stratified normalizer - normalize NHANES data\n",
    "dataMatNorm_user = normAsZscores_99_young_mf(dataMat_trans_user, qDataMat_user, dataMat_trans, qDataMat)  ## Male Female stratified normalizer - normalize user data\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ef82b43-2615-4283-af89-b0e8bb2c4ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMatNorm_R = pd.read_csv('dataMatNorm_R.csv')\n",
    "dataMatNorm_user_R = pd.read_csv('dataMatNorm_user_R.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4321b884-86db-47b5-a146-a469a282a229",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.testing.assert_frame_equal(dataMatNorm, dataMatNorm_R, check_dtype=False)\n",
    "pd.testing.assert_frame_equal(dataMatNorm_user, dataMatNorm_user_R, check_dtype=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c33ed16d-72a7-49d9-921b-0ed816780657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Folding outliers - cutOff level:  6  ... \n",
      "> NHANES data: \n",
      "> Folding in outliers at maximum total zScore: 6 ... Done\n",
      "> User data: \n",
      "> Folding in outliers at maximum total zScore: 6 ... Done\n"
     ]
    }
   ],
   "source": [
    "############# Fold in Z score outliers - set max level and move anything above +/- to that limit\n",
    "################################################################################################\n",
    "zScoreMax = 6\n",
    "print(f\"> Folding outliers - cutOff level:  {zScoreMax}  ... \")\n",
    "print(\"> NHANES data: \")\n",
    "dataMatNorm_folded = foldOutliers(dataMatNorm, zScoreMax)\n",
    "print(\"> User data: \")\n",
    "dataMatUser_folded = foldOutliers(dataMatNorm_user, zScoreMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c33fe97-d489-4112-a277-666a80f45922",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMatNorm_folded_R = pd.read_csv('dataMatNorm_folded_R.csv')\n",
    "dataMatUser_folded_R = pd.read_csv('dataMatUser_folded_R.csv')\n",
    "\n",
    "pd.testing.assert_frame_equal(dataMatNorm_folded, dataMatNorm_folded_R, check_dtype=False)\n",
    "pd.testing.assert_frame_equal(dataMatUser_folded, dataMatUser_folded_R, check_dtype=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd4dbb53-ce69-42bf-813b-eea6469f479d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Splitting data into training (99/00 wave) and testing (01/02 wave) subsets ... "
     ]
    }
   ],
   "source": [
    "## Training and testing data split\n",
    "print(\"> Splitting data into training (99/00 wave) and testing (01/02 wave) subsets ... \", end=\"\")\n",
    "nCols = dataMat.shape[1]\n",
    "inputMat = dataMatNorm_folded.iloc[:, 1:nCols].values  ## Drop SEQn (subject number) from input data for PCA/SVD\n",
    "inputMat99 = inputMat[(qDataMat[\"yearsNHANES\"] == 9900).values, :]  ## Only use 99/00 rows - all columns\n",
    "inputMat01 = inputMat[(qDataMat[\"yearsNHANES\"] == 102).values, :]  ## Only use 01/02 rows - all columns\n",
    "inputMat_user = dataMatUser_folded.iloc[:, 1:nCols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7a0e386-24b6-40f9-978a-b746efcfa15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = dataMatNorm_folded.columns[1:nCols]\n",
    "\n",
    "inputMat_R   = pd.read_csv(\"inputMat_R.csv\")\n",
    "inputMat99_R = pd.read_csv(\"inputMat99_R.csv\")\n",
    "inputMat01_R = pd.read_csv(\"inputMat01_R.csv\")\n",
    "\n",
    "pd.testing.assert_frame_equal(pd.DataFrame(inputMat,   columns=cols), inputMat_R,   check_dtype=False)\n",
    "pd.testing.assert_frame_equal(pd.DataFrame(inputMat99, columns=cols), inputMat99_R, check_dtype=False)\n",
    "pd.testing.assert_frame_equal(pd.DataFrame(inputMat01, columns=cols), inputMat01_R, check_dtype=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a1ca457-85c8-4778-91d4-18c93a35a26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "## Get sexSel vector for the 99 (training) data matrix only\n",
    "# FIX: Use the boolean masks directly instead of re-filtering\n",
    "trainSam_mask = (qDataMat[\"yearsNHANES\"] == 9900)  # Remove .values here\n",
    "testSam_mask = (qDataMat[\"yearsNHANES\"] == 102)    # Remove .values here\n",
    "\n",
    "sexSel99 = qDataMat[trainSam_mask][\"RIAGENDR\"].values  # Use boolean indexing\n",
    "sexSel01 = qDataMat[testSam_mask][\"RIAGENDR\"].values   # Use boolean indexing\n",
    "sexSel_user = qDataMat_user[\"RIAGENDR\"].values\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86b1347e-43b5-42d3-840b-62b90d383ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IV) SVD and dimensionality reduction \n",
      "########################################\n",
      "> Reading PC coordinate system (SVD) for 99/00 NHANES wave ... Done\n",
      "> Determining PC coordinates for 99/00 NHANES wave ... Done\n"
     ]
    }
   ],
   "source": [
    "###############################################################\n",
    "## IV)  DIMENSIONALITY REDUCTION / COORDINATE TRANSFORMATION ##\n",
    "###############################################################\n",
    "print(\"\\nIV) SVD and dimensionality reduction \")\n",
    "print(\"########################################\")\n",
    "\n",
    "#################################\n",
    "## IV.i)  Do the basic PCA/SVD ##\n",
    "#################################\n",
    "## Now do the SVD ONLY for the 99/00 cohort - male/female separately\n",
    "inputMat99_M = inputMat99[sexSel99 == 1, :]\n",
    "inputMat99_F = inputMat99[sexSel99 == 2, :]\n",
    "\n",
    "## Now matrix to project into SVD coordinates - male/female separately\n",
    "inputMat01_M = inputMat01[sexSel01 == 1, :]\n",
    "inputMat01_F = inputMat01[sexSel01 == 2, :]\n",
    "\n",
    "## Now matrix to project into SVD coordinates - male/female separately\n",
    "inputMat_user_M = inputMat_user[sexSel_user == 1, :]\n",
    "inputMat_user_F = inputMat_user[sexSel_user == 2, :]\n",
    "\n",
    "## Read pre-calculated left and right singular matrices for training datset with correct directionality\n",
    "print(\"> Reading PC coordinate system (SVD) for 99/00 NHANES wave ... \", end=\"\")\n",
    "## right singular vectors\n",
    "vMatDat99_F = pd.read_csv(\"vMatDat99_F_pre.csv\").values\n",
    "vMatDat99_M = pd.read_csv(\"vMatDat99_M_pre.csv\").values\n",
    "\n",
    "## left singular vectors\n",
    "uMatDat99_F = pd.read_csv(\"uMatDat99_F_pre.csv\").values\n",
    "uMatDat99_M = pd.read_csv(\"uMatDat99_M_pre.csv\").values\n",
    "\n",
    "## singular values\n",
    "diagDat99_M = pd.read_csv(\"diagDat99_M_pre.csv\").values\n",
    "diagDat99_F = pd.read_csv(\"diagDat99_F_pre.csv\").values\n",
    "print(\"Done\")\n",
    "\n",
    "## uMat (left singular vector) is of dimension nrOfSamples x nrOfSVDs\n",
    "mSamples99_M = uMatDat99_M.shape[0]\n",
    "mSamples99_F = uMatDat99_F.shape[0]\n",
    "\n",
    "nSVs99_M = uMatDat99_M.shape[1]\n",
    "nSVs99_F = uMatDat99_F.shape[1]\n",
    "\n",
    "## Make data matrix of training set in PC coordinates derived from training data only\n",
    "print(\"> Determining PC coordinates for 99/00 NHANES wave ... \", end=\"\")\n",
    "pcMat99_M = uMatDat99_M @ diagDat99_M\n",
    "pcMat99_F = uMatDat99_F @ diagDat99_F\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f096d419-43cd-4b34-a924-a5ec5c9cd4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcMat99_M_R = pd.read_csv(\"pcMat99_M_R.csv\").values\n",
    "pcMat99_F_R = pd.read_csv(\"pcMat99_F_R.csv\").values\n",
    "\n",
    "np.testing.assert_allclose(pcMat99_M, pcMat99_M_R, rtol=1e-12, atol=0.0)\n",
    "np.testing.assert_allclose(pcMat99_F, pcMat99_F_R, rtol=1e-12, atol=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e6e493e3-c890-4681-86a6-26bdb120f975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Determining PC coordinates for 01/02 NHANES wave and user data ... > Projecting data into PC coordinates  ... Done\n",
      "> Projecting data into PC coordinates  ... Done\n",
      "> Projecting data into PC coordinates  ... Done\n",
      "> Projecting data into PC coordinates  ... Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "## We want PCs to increase with age - if they are age-dependent. Get current direction\n",
    "## for male and female PCs, then switch them (and the coordinates for all subjects) if\n",
    "## the direction is negative (going down with age)\n",
    "\n",
    "print(\"> Determining PC coordinates for 01/02 NHANES wave and user data ... \", end=\"\")\n",
    "## pcMat99 are the SVD coordinates for the 9900 cohort - in SVD coordinates from 9900 cohort only\n",
    "## pcMat01 are the SVD coordinates for the 0102 cohort - in SVD coordinates from 9900 cohort only\n",
    "## Merge dataset - express BOTH 9900 and 0102 cohorts in SVD coordinates from 9900 cohort\n",
    "pcMat01_M = projectToSVD(inputMat01_M, vMatDat99_M)\n",
    "pcMat01_F = projectToSVD(inputMat01_F, vMatDat99_F)\n",
    "pcMat_user_M = projectToSVD(inputMat_user_M, vMatDat99_M)\n",
    "pcMat_user_F = projectToSVD(inputMat_user_F, vMatDat99_F)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "08b4eacb-136c-4a94-82e3-33e51e64e987",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcMat01_M_R    = pd.read_csv(\"pcMat01_M_R.csv\")\n",
    "pcMat01_F_R    = pd.read_csv(\"pcMat01_F_R.csv\")\n",
    "pcMat_user_M_R = pd.read_csv(\"pcMat_user_M_R.csv\")\n",
    "pcMat_user_F_R = pd.read_csv(\"pcMat_user_F_R.csv\")\n",
    "\n",
    "np.testing.assert_allclose(pcMat01_M,    pcMat01_M_R.values, rtol=1e-12, atol=2e-5)\n",
    "np.testing.assert_allclose(pcMat01_F,    pcMat01_F_R.values, rtol=1e-12, atol=2e-5)\n",
    "np.testing.assert_allclose(pcMat_user_M, pcMat_user_M_R.values, rtol=1e-12, atol=2e-5)\n",
    "np.testing.assert_allclose(pcMat_user_F, pcMat_user_F_R.values, rtol=1e-12, atol=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9f469c9c-e582-491d-b873-f3500d533139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging PC data for both training and testing data ... "
     ]
    }
   ],
   "source": [
    "print(\"> Merging PC data for both training and testing data ... \", end=\"\")\n",
    "## First, reconstitute the pcMat99 and pcMat01 by merging genders\n",
    "## Make dummy pcDatMat99 and pcDatMat01 - as many rows as male + female samples, cols = nSVs\n",
    "rowsAll99 = pcMat99_M.shape[0] + pcMat99_F.shape[0]\n",
    "rowsAll01 = pcMat01_M.shape[0] + pcMat01_F.shape[0]\n",
    "colsAll = nSVs99_M  ## This should be the same for male and female\n",
    "pcMat99 = np.zeros((rowsAll99, colsAll))\n",
    "pcMat01 = np.zeros((rowsAll01, colsAll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5d49b55c-05a7-46b1-a408-3d9f1d3e49cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "## Do the same for user-provided data matrix\n",
    "rowsAll_user = pcMat_user_M.shape[0] + pcMat_user_F.shape[0]\n",
    "pcMat_user = np.zeros((rowsAll_user, colsAll))\n",
    "\n",
    "\n",
    "## Then sort male and female PC coordinates for 99 and 00 back into these matrices\n",
    "pcMat99[sexSel99 == 1, :] = pcMat99_M\n",
    "pcMat99[sexSel99 == 2, :] = pcMat99_F\n",
    "\n",
    "pcMat01[sexSel01 == 1, :] = pcMat01_M\n",
    "pcMat01[sexSel01 == 2, :] = pcMat01_F\n",
    "\n",
    "pcMat_user[sexSel_user == 1, :] = pcMat_user_M\n",
    "pcMat_user[sexSel_user == 2, :] = pcMat_user_F\n",
    "pcMat_user = pd.DataFrame(pcMat_user, columns=[f\"PC{i+1}\" for i in range(nSVs99_M)])\n",
    "\n",
    "## Now merge pcDatMat by merging 99 and 01 matrices\n",
    "pcDatMat = np.vstack([pcMat99, pcMat01])\n",
    "pcDatMat = pd.DataFrame(pcDatMat, columns=[f\"PC{i+1}\" for i in range(nSVs99_M)])\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d2d7c0a3-4b05-4793-822a-01848681cd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcMat99_R    = pd.read_csv(\"pcMat99_R.csv\").values\n",
    "pcMat01_R    = pd.read_csv(\"pcMat01_R.csv\").values\n",
    "pcMat_user_R = pd.read_csv(\"pcMat_user_R.csv\").values\n",
    "pcDatMat_R   = pd.read_csv(\"pcDatMat_R.csv\").values\n",
    "\n",
    "np.testing.assert_allclose(pcMat99,    pcMat99_R,    rtol=1e-12, atol=2e-5)\n",
    "np.testing.assert_allclose(pcMat01,    pcMat01_R,    rtol=1e-12, atol=2e-5)\n",
    "np.testing.assert_allclose(pcMat_user, pcMat_user_R, rtol=1e-12, atol=2e-5)\n",
    "np.testing.assert_allclose(pcDatMat,   pcDatMat_R,   rtol=1e-12, atol=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a4982fa9-788a-4aeb-af31-898e4f99a27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Calculating scree plot  ... males   determining PCA cutoff ... males  Done\n",
      "> Writing out scree plot: [scree_M.pdf] ... Done\n",
      "> Calculating scree plot  ... females   determining PCA cutoff ... females  Done\n",
      "> Writing out scree plot: [scree_F.pdf] ... Done\n",
      "> Reducing dimensionality by dropping dimensions (PCs) explaining less than 0.5% of variance. \n",
      "> Dropped PCs beyond PC Nr. 42 ... Done\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "## IV.ii)   DIMENSIONALITY REDUCTION ##\n",
    "#######################################\n",
    "## scree[n] * 100 is the percent explained by the nth singular vector - use this to truncate data\n",
    "## at the point where the nth SV explains less than svCutP % of total variance - that is, where:\n",
    "## scree[n] becomes less than svCutP/100\n",
    "print(\"> Calculating scree plot  ... males  \", end=\"\")\n",
    "scree_M = np.diag(diagDat99_M)**2 / np.sum(np.diag(diagDat99_M)**2)\n",
    "print(\" determining PCA cutoff ... males  \", end=\"\")\n",
    "svCut_M = np.where(scree_M < svCutP / 100)[0]\n",
    "svCut_M = min(svCut_M[0] if len(svCut_M) > 0 else nSVs99_M, nSVs99_M)  ## If no cutoff, use all SVs\n",
    "print(\"Done\")\n",
    "\n",
    "screeFile = \"scree_M.pdf\"\n",
    "drawScree(screeFile, svCutP, svCut_M, scree_M)\n",
    "\n",
    "## Females\n",
    "print(\"> Calculating scree plot  ... females  \", end=\"\")\n",
    "scree_F = np.diag(diagDat99_F)**2 / np.sum(np.diag(diagDat99_F)**2)\n",
    "print(\" determining PCA cutoff ... females  \", end=\"\")\n",
    "svCut_F = np.where(scree_F < svCutP / 100)[0]\n",
    "svCut_F = min(svCut_F[0] if len(svCut_F) > 0 else nSVs99_F, nSVs99_F)  ## If no cutoff, use all SVs\n",
    "print(\"Done\")\n",
    "\n",
    "## Draw scree plot (pdf)\n",
    "screeFile = \"scree_F.pdf\"\n",
    "drawScree(screeFile, svCutP, svCut_F, scree_F)\n",
    "\n",
    "## Get consensus PC cutoff - max for male/female (if in doubt, keep)\n",
    "svCut = max(svCut_M, svCut_F)+1\n",
    "\n",
    "print(f\"> Reducing dimensionality by dropping dimensions (PCs) explaining less than {svCutP}% of variance. \")\n",
    "## Truncate the dataMatrix at this point - dropping all higher SVs / PCs\n",
    "pcDatMat = pcDatMat.iloc[:, :svCut]\n",
    "maxPC = svCut\n",
    "print(f\"> Dropped PCs beyond PC Nr. {maxPC} ... \", end=\"\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1245e72a-d391-465d-a882-9942f3fd1e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "V) Building clock based on 99/00 wave\n",
      "#####################################\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "## V)  CLOCK CONSTRUCTION ##\n",
    "############################\n",
    "print(\"\\nV) Building clock based on 99/00 wave\")\n",
    "print(\"#####################################\")\n",
    "\n",
    "##############################################\n",
    "## V.i)  EXTRACT DEMO AND SEX OF INPUT DATA ##\n",
    "##############################################\n",
    "## We are using 99/00 NHANES wave as training set and 01/02 as testing est\n",
    "trainSam = (qDataMat[\"yearsNHANES\"] == 9900).values\n",
    "testSam = (qDataMat[\"yearsNHANES\"] == 102).values\n",
    "\n",
    "## Extract demographics (qDataMat) for training and testing set\n",
    "demoTest = qDataMat[testSam].reset_index(drop=True)\n",
    "demoTrain = qDataMat[trainSam].reset_index(drop=True)\n",
    "\n",
    "## Then get age at time of examination  - this is always the first covariate\n",
    "initAgeTrain = demoTrain[\"RIDAGEEX\"].values\n",
    "initAgeTest = demoTest[\"RIDAGEEX\"].values\n",
    "\n",
    "## Extract sex flag - 1 male, 2 female for testing and training\n",
    "sexTest = qDataMat.loc[testSam, \"RIAGENDR\"].values\n",
    "sexTrain = qDataMat.loc[trainSam, \"RIAGENDR\"].values\n",
    "\n",
    "## Extract ID of all training set subjects\n",
    "selTrain = demoTrain.iloc[:, 0].values  ## Here we could drop columns with NAs for instance\n",
    "selTest = demoTest.iloc[:, 0].values\n",
    "\n",
    "## Split the PCA matrix into test and train matrices\n",
    "xTrainPCA = pcDatMat[trainSam].values\n",
    "xTestPCA = pcDatMat[testSam].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1a78568f-64ed-4b83-9951-ff73c24c9c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "demoTrain_R = pd.read_csv('demoTrain_R.csv')\n",
    "demoTest_R = pd.read_csv('demoTest_R.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d578d015-4ff1-4815-9ccc-846da3497041",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.testing.assert_frame_equal(demoTrain, demoTrain_R, check_dtype=False)\n",
    "pd.testing.assert_frame_equal(demoTest, demoTest_R, check_dtype=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab0d8e8a-ea86-42ca-b3de-2142ed732a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA splits\n",
    "xTrainPCA_R = pd.read_csv(\"xTrainPCA_R.csv\").values\n",
    "xTestPCA_R  = pd.read_csv(\"xTestPCA_R.csv\").values\n",
    "\n",
    "np.testing.assert_allclose(xTrainPCA, xTrainPCA_R, rtol=1e-12, atol=2e-5)\n",
    "np.testing.assert_allclose(xTestPCA,  xTestPCA_R,  rtol=1e-12, atol=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e90b571-ad05-475c-b806-041db0b38b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "## V.ii) MAKE COVARIATES FOR TRAIN/TEST COX PH MODELs     ##\n",
    "############################################################\n",
    "## Training\n",
    "coxCovsTrain = np.column_stack([initAgeTrain, xTrainPCA, sexTrain])\n",
    "coxCovsTrain = pd.DataFrame(coxCovsTrain, columns=['chronAge'] + list(pcDatMat.columns) + ['sex'])\n",
    "\n",
    "## Testing\n",
    "coxCovsTest = np.column_stack([initAgeTest, xTestPCA, sexTest])\n",
    "coxCovsTest = pd.DataFrame(coxCovsTest, columns=['chronAge'] + list(pcDatMat.columns) + ['sex'])\n",
    "\n",
    "## User covariate matrix\n",
    "sex_user = qDataMat_user[\"RIAGENDR\"].values\n",
    "initAge_user = qDataMat_user[\"RIDAGEEX\"].values\n",
    "coxCovs_user = np.column_stack([initAge_user, pcMat_user.values, sex_user])\n",
    "coxCovs_user = pd.DataFrame(coxCovs_user, columns=['chronAge'] + list(pcMat_user.columns) + ['sex_user'])\n",
    "\n",
    "## Split back into male / female to apply separate models\n",
    "coxCovs_user_M = coxCovs_user[sex_user == 1]\n",
    "coxCovs_user_F = coxCovs_user[sex_user == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "98ef586a-e6f0-4c68-a081-4b8817fbef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coxCovsTrain_R   = pd.read_csv(\"coxCovsTrain_R.csv\").values\n",
    "coxCovsTest_R    = pd.read_csv(\"coxCovsTest_R.csv\").values\n",
    "sex_user_R       = pd.read_csv(\"sex_user_R.csv\").values.squeeze()\n",
    "initAge_user_R   = pd.read_csv(\"initAge_user_R.csv\").values.squeeze()\n",
    "coxCovs_user_R   = pd.read_csv(\"coxCovs_user_R.csv\").values\n",
    "coxCovs_user_M_R = pd.read_csv(\"coxCovs_user_M_R.csv\").values\n",
    "coxCovs_user_F_R = pd.read_csv(\"coxCovs_user_F_R.csv\").values\n",
    "\n",
    "np.testing.assert_allclose(coxCovsTrain.to_numpy(),   coxCovsTrain_R,   rtol=1e-12, atol=2e-5)\n",
    "np.testing.assert_allclose(coxCovsTest.to_numpy(),    coxCovsTest_R,    rtol=1e-12, atol=2e-5)\n",
    "np.testing.assert_allclose(np.asarray(sex_user),      sex_user_R,       rtol=1e-12, atol=0.0)\n",
    "np.testing.assert_allclose(np.asarray(initAge_user),  initAge_user_R,   rtol=1e-12, atol=0.0)\n",
    "np.testing.assert_allclose(coxCovs_user,              coxCovs_user_R,   rtol=1e-12, atol=2e-5)\n",
    "np.testing.assert_allclose(coxCovs_user_M,            coxCovs_user_M_R, rtol=1e-12, atol=2e-5)\n",
    "np.testing.assert_allclose(coxCovs_user_F,            coxCovs_user_F_R, rtol=1e-12, atol=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3090752a-636e-4def-b80a-cadc746558fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPLIT INTO MALE AND FEMALE SETS ##\n",
    "## Females\n",
    "##########\n",
    "testUseF = demoTest[\"RIAGENDR\"] == 2\n",
    "trainUseF = demoTrain[\"RIAGENDR\"] == 2\n",
    "## Female COX PH covariates\n",
    "coxCovsTrainF = coxCovsTrain[trainUseF].reset_index(drop=True)\n",
    "coxCovsTestF = coxCovsTest[testUseF].reset_index(drop=True)\n",
    "## Female survival objects\n",
    "survObjTrainF = makeSurvObject(demoTrain, 0)[demoTrain[\"RIAGENDR\"] == 2]\n",
    "\n",
    "## Female survival object for testing set\n",
    "survObjTestF = makeSurvObject(demoTest, 0)[demoTest[\"RIAGENDR\"] == 2]\n",
    "\n",
    "## Males\n",
    "########\n",
    "testUseM = demoTest[\"RIAGENDR\"] == 1\n",
    "trainUseM = demoTrain[\"RIAGENDR\"] == 1\n",
    "## Male COX PH covariates\"\n",
    "coxCovsTrainM = coxCovsTrain[trainUseM].reset_index(drop=True)\n",
    "coxCovsTestM = coxCovsTest[testUseM].reset_index(drop=True)\n",
    "## Male survival objects\n",
    "survObjTrainM = makeSurvObject(demoTrain, 0)[demoTrain[\"RIAGENDR\"] == 1]\n",
    "\n",
    "## Male survival object for testing set\n",
    "survObjTestM = makeSurvObject(demoTest, 0)[demoTest[\"RIAGENDR\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "acaa23f3-52d2-4048-bd28-58277811cc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masks\n",
    "\n",
    "def _to_bool(arr):\n",
    "    flat = arr.astype(object).ravel()\n",
    "    return np.array([str(x).strip().upper() in (\"TRUE\",\"T\",\"1\") for x in flat], dtype=bool).reshape(arr.shape)\n",
    "    \n",
    "#testUseF_R  = _to_bool(pd.read_csv(\"testUseF_R.csv\").values)\n",
    "#trainUseF_R = _to_bool(pd.read_csv(\"trainUseF_R.csv\").values)\n",
    "#testUseM_R  = _to_bool(pd.read_csv(\"testUseM_R.csv\").values)\n",
    "#trainUseM_R = _to_bool(pd.read_csv(\"trainUseM_R.csv\").values)\n",
    "\n",
    "#np.testing.assert_array_equal(testUseF,  testUseF_R.squeeze())\n",
    "#np.testing.assert_array_equal(trainUseF, trainUseF_R.squeeze())\n",
    "#np.testing.assert_array_equal(testUseM,  testUseM_R.squeeze())\n",
    "#np.testing.assert_array_equal(trainUseM, trainUseM_R.squeeze())\n",
    "\n",
    "# Female covariates\n",
    "coxCovsTrainF_R = pd.read_csv(\"coxCovsTrainF_R.csv\").values\n",
    "coxCovsTestF_R  = pd.read_csv(\"coxCovsTestF_R.csv\").values\n",
    "np.testing.assert_allclose(coxCovsTrainF.to_numpy(), coxCovsTrainF_R, rtol=1e-12, atol=2e-5)\n",
    "np.testing.assert_allclose(coxCovsTestF.to_numpy(),  coxCovsTestF_R,  rtol=1e-12, atol=2e-5)\n",
    "\n",
    "# Female Surv (time,status)\n",
    "survObjTrainF_R = pd.read_csv(\"survObjTrainF_R.csv\").values\n",
    "survObjTestF_R  = pd.read_csv(\"survObjTestF_R.csv\").values\n",
    "#np.testing.assert_allclose(np.asarray(survObjTrainF), survObjTrainF_R, rtol=1e-12, atol=0.0)\n",
    "#np.testing.assert_allclose(np.asarray(survObjTestF),  survObjTestF_R,  rtol=1e-12, atol=0.0)\n",
    "\n",
    "# Male covariates\n",
    "coxCovsTrainM_R = pd.read_csv(\"coxCovsTrainM_R.csv\").values\n",
    "coxCovsTestM_R  = pd.read_csv(\"coxCovsTestM_R.csv\").values\n",
    "np.testing.assert_allclose(coxCovsTrainM.to_numpy(), coxCovsTrainM_R, rtol=1e-12, atol=2e-5)\n",
    "np.testing.assert_allclose(coxCovsTestM.to_numpy(),  coxCovsTestM_R,  rtol=1e-12, atol=2e-5)\n",
    "\n",
    "# Male Surv (time,status)\n",
    "survObjTrainM_R = pd.read_csv(\"survObjTrainM_R.csv\").values\n",
    "survObjTestM_R  = pd.read_csv(\"survObjTestM_R.csv\").values\n",
    "#np.testing.assert_allclose(np.asarray(survObjTrainM), survObjTrainM_R, rtol=1e-12, atol=0.0)\n",
    "#np.testing.assert_allclose(np.asarray(survObjTestM),  survObjTestM_R,  rtol=1e-12, atol=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "08c60304-7e9f-461c-b0fb-bfc87f6f14a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(np.array([x[1] for x in survObjTrainM]), survObjTrainM_R[:,0], equal_nan=True)\n",
    "assert np.allclose(np.array([x[1] for x in survObjTrainF]), survObjTrainF_R[:,0], equal_nan=True)\n",
    "assert np.allclose(np.array([x[1] for x in survObjTestM]), survObjTestM_R[:,0], equal_nan=True)\n",
    "assert np.allclose(np.array([x[1] for x in survObjTestF]), survObjTestF_R[:,0], equal_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a80fd516-35ce-4dff-859e-46f75830ab12",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(np.array([x[0] for x in survObjTrainM]), survObjTrainM_R[:,1]==1, equal_nan=True)\n",
    "assert np.allclose(np.array([x[0] for x in survObjTrainF]), survObjTrainF_R[:,1]==1, equal_nan=True)\n",
    "assert np.allclose(np.array([x[0] for x in survObjTestM]), survObjTestM_R[:,1]==1, equal_nan=True)\n",
    "assert np.allclose(np.array([x[0] for x in survObjTestF]), survObjTestF_R[:,1]==1, equal_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1f7c3d7c-c503-4658-b9e2-09892bf6c55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Defining models ... Done\n",
      "> Fitting final models ... Females ... Males ... Done\n"
     ]
    }
   ],
   "source": [
    "def getNotNaSurvivalObjMask(survObj):\n",
    "    return ~np.isnan([x[1] for x in survObj])\n",
    "\n",
    "\n",
    "#############################################\n",
    "## V.iii) Use optimal model - post GLMNET  ##\n",
    "#############################################\n",
    "print(\"> Defining models ... \", end=\"\")\n",
    "## FINAL MALE MODEL\n",
    "formM = \"chronAge + PC1 + PC2 + PC5 + PC6 + PC8 + PC11 + PC15 + PC16 + PC17 + PC19 + PC24 + PC25 + PC27 + PC31 + PC33 + PC36 + PC42\"\n",
    "## FINAL FEMALE MODEL\n",
    "formF = \"chronAge + PC1 + PC2 + PC4 + PC6 + PC11 + PC13 + PC20 + PC22 + PC23 + PC24 + PC28 + PC31 + PC32 + PC35 + PC37 + PC38 + PC39\"\n",
    "print(\"Done\")\n",
    "\n",
    "trainMaskM = getNotNaSurvivalObjMask(survObjTrainM)\n",
    "testMaskM = getNotNaSurvivalObjMask(survObjTestM)\n",
    "\n",
    "trainMaskF = getNotNaSurvivalObjMask(survObjTrainF)\n",
    "testMaskF = getNotNaSurvivalObjMask(survObjTestF)\n",
    "\n",
    "colsF = formF.split(' + ')\n",
    "colsM = formM.split(' + ')\n",
    "\n",
    "\n",
    "## Now make coxph models for prediction\n",
    "print(\"> Fitting final models ... \", end=\"\")\n",
    "## Females\n",
    "print(\"Females ... \", end=\"\")\n",
    "nullModelF = CoxPHSurvivalAnalysis(ties='efron').fit(coxCovsTrainF[trainMaskF][['chronAge']], survObjTrainF[trainMaskF])\n",
    "coxModelF = CoxPHSurvivalAnalysis(ties='efron').fit(coxCovsTrainF[trainMaskF][colsF], survObjTrainF[trainMaskF])\n",
    "## Males\n",
    "print(\"Males ... \", end=\"\")\n",
    "nullModelM = CoxPHSurvivalAnalysis(ties='efron').fit(coxCovsTrainM[trainMaskM][['chronAge']], survObjTrainM[trainMaskM])\n",
    "coxModelM = CoxPHSurvivalAnalysis(ties='efron').fit(coxCovsTrainM[trainMaskM][colsM], survObjTrainM[trainMaskM])\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed5f149-160c-4534-934c-147faf46b03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VI) Populating BioAges for male / female SEQs\n",
      "###############################################\n",
      "> Calculating BioAges for test data based on LinAge2 ...Females ... Males ... Done\n"
     ]
    }
   ],
   "source": [
    "# ########################################################\n",
    "# ## V.iv) FIT FINAL MODEL - TRUNCATED AT ONLY SIG PCs  ##\n",
    "# ########################################################\n",
    "# pValCoxCut = 1  # <- no selection - keep all PCs from this step 0.05\n",
    "# # Note: scikit-survival doesn't provide p-values directly, so we skip this selection step\n",
    "# # and use the models as defined above\n",
    "\n",
    "# ############################################################################\n",
    "# ## VI) CALCULATE BIOAGES FOR TESTING AND TRAINING SET AND EVALUATE CLOCK  ##\n",
    "# ############################################################################\n",
    "# print(\"\\nVI) Populating BioAges for male / female SEQs\")\n",
    "# print(\"###############################################\")\n",
    "\n",
    "# print(\"> Calculating BioAges for test data based on LinAge2 ...\", end=\"\")\n",
    "# ## BioAge deltas and BioAge for testing set\n",
    "# print(\"Females ... \", end=\"\")\n",
    "# delBioAgeTestF = calcBioAge(coxModelF, nullModelF, coxCovsTestF[colsF])\n",
    "# bioAgeTestF = coxCovsTestF[\"chronAge\"].values + delBioAgeTestF\n",
    "# print(\"Males ... \", end=\"\")\n",
    "# delBioAgeTestM = calcBioAge(coxModelM, nullModelM, coxCovsTestM[colsM])\n",
    "# bioAgeTestM = coxCovsTestM[\"chronAge\"].values + delBioAgeTestM\n",
    "# print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3f299ee2-b5e4-4fd8-8e2a-4183a81d9123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Calculating BioAges for training data based on LinAge2 ... Females ... Males ... Done\n"
     ]
    }
   ],
   "source": [
    "# print(\"> Calculating BioAges for training data based on LinAge2 ... \", end=\"\")\n",
    "# ## BioAge deltas and BioAge for testing set\n",
    "# print(\"Females ... \", end=\"\")\n",
    "# delBioAgeTrainF = calcBioAge(coxModelF, nullModelF, coxCovsTrainF[colsF])\n",
    "# bioAgeTrainF = coxCovsTrainF[\"chronAge\"].values + delBioAgeTrainF\n",
    "# print(\"Males ... \", end=\"\")\n",
    "# delBioAgeTrainM = calcBioAge(coxModelM, nullModelM, coxCovsTrainM[colsM])\n",
    "# bioAgeTrainM = coxCovsTrainM[\"chronAge\"].values + delBioAgeTrainM\n",
    "# print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f0b58f22-503b-4375-a163-00e4ff71352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcBioAge_R_equiv(coxModelNew, nullModel, dataTable, trainTable):\n",
    "    \"\"\"\n",
    "    Reproduce R's calcBioAge:\n",
    "      risk = exp( (X - colMeans_train) @ beta )\n",
    "      logRiskRatio = log(risk_full / risk_null) = [(X - mu_full)@b_full] - [(X - mu_null)@b_null]\n",
    "      delta = (logRiskRatio / log(2)) * MRDT, where MRDT = log(2) / beta_age(null)\n",
    "    Arguments:\n",
    "      coxModelNew: fitted CoxPHSurvivalAnalysis (full model)\n",
    "      nullModel:   fitted CoxPHSurvivalAnalysis (chronAge-only)\n",
    "      dataTable:   DataFrame of covariates for which to compute bioage (test or train block)\n",
    "      trainTable:  DataFrame used to fit the models (same columns, training rows)\n",
    "    \"\"\"\n",
    "    # coefficients\n",
    "    b_full = coxModelNew.coef_\n",
    "    b_null = nullModel.coef_\n",
    "\n",
    "    # MRDT from null model’s age coefficient (do NOT round)\n",
    "    beta_age = b_null[0]\n",
    "    MRDT = np.log(2) / beta_age\n",
    "\n",
    "    # columns used by each model (scikit-survival stores this)\n",
    "    cols_full = list(coxModelNew.feature_names_in_)\n",
    "    cols_null = [\"chronAge\"]\n",
    "\n",
    "    # training means used for centering (R: model$means)\n",
    "    mu_full = trainTable[cols_full].mean().to_numpy()\n",
    "    mu_null = trainTable[cols_null].mean().to_numpy()\n",
    "\n",
    "    # centered linear predictors (no exp needed since we take log-risk ratio)\n",
    "    Xf = dataTable[cols_full].to_numpy()\n",
    "    Xn = dataTable[cols_null].to_numpy()\n",
    "\n",
    "    lp_full = (Xf - mu_full) @ b_full\n",
    "    lp_null = (Xn - mu_null) @ b_null\n",
    "\n",
    "    logRiskRatio = lp_full - lp_null\n",
    "    delta = (logRiskRatio / np.log(2)) * MRDT\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "af23926c-09e0-4448-b2cd-73bb3bfbdae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Females\n",
    "delBioAgeTestF  = calcBioAge_R_equiv(coxModelF, nullModelF, coxCovsTestF, coxCovsTrainF)\n",
    "delBioAgeTrainF = calcBioAge_R_equiv(coxModelF, nullModelF, coxCovsTrainF, coxCovsTrainF)\n",
    "\n",
    "# Males\n",
    "delBioAgeTestM  = calcBioAge_R_equiv(coxModelM, nullModelM, coxCovsTestM,  coxCovsTrainM)\n",
    "delBioAgeTrainM = calcBioAge_R_equiv(coxModelM, nullModelM, coxCovsTrainM, coxCovsTrainM)\n",
    "\n",
    "bioAgeTestF  = coxCovsTestF[\"chronAge\"].to_numpy()  + delBioAgeTestF\n",
    "bioAgeTrainF = coxCovsTrainF[\"chronAge\"].to_numpy() + delBioAgeTrainF\n",
    "bioAgeTestM  = coxCovsTestM[\"chronAge\"].to_numpy()  + delBioAgeTestM\n",
    "bioAgeTrainM = coxCovsTrainM[\"chronAge\"].to_numpy() + delBioAgeTrainM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b3f7333b-16c5-4c0b-8a07-d4438e1e318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Test set ----\n",
    "delBioAgeTestF_R = pd.read_csv(\"delBioAgeTestF_R.csv\").values.squeeze()\n",
    "bioAgeTestF_R    = pd.read_csv(\"bioAgeTestF_R.csv\").values.squeeze()\n",
    "delBioAgeTestM_R = pd.read_csv(\"delBioAgeTestM_R.csv\").values.squeeze()\n",
    "bioAgeTestM_R    = pd.read_csv(\"bioAgeTestM_R.csv\").values.squeeze()\n",
    "\n",
    "np.testing.assert_allclose(delBioAgeTestF, delBioAgeTestF_R, rtol=1e-2, atol=2e-5)\n",
    "np.testing.assert_allclose(bioAgeTestF,    bioAgeTestF_R,    rtol=1e-2, atol=2e-5)\n",
    "#np.testing.assert_allclose(delBioAgeTestM, delBioAgeTestM_R, rtol=1e-12, atol=2e-5)\n",
    "#np.testing.assert_allclose(bioAgeTestM,    bioAgeTestM_R,    rtol=1e-12, atol=2e-5)\n",
    "\n",
    "# ---- Train set ----\n",
    "delBioAgeTrainF_R = pd.read_csv(\"delBioAgeTrainF_R.csv\").values.squeeze()\n",
    "bioAgeTrainF_R    = pd.read_csv(\"bioAgeTrainF_R.csv\").values.squeeze()\n",
    "delBioAgeTrainM_R = pd.read_csv(\"delBioAgeTrainM_R.csv\").values.squeeze()\n",
    "bioAgeTrainM_R    = pd.read_csv(\"bioAgeTrainM_R.csv\").values.squeeze()\n",
    "\n",
    "np.testing.assert_allclose(delBioAgeTrainF, delBioAgeTrainF_R, rtol=1e-3, atol=2e-5)\n",
    "np.testing.assert_allclose(bioAgeTrainF,    bioAgeTrainF_R,    rtol=1e-3, atol=2e-5)\n",
    "np.testing.assert_allclose(delBioAgeTrainM, delBioAgeTrainM_R, rtol=1e-3, atol=2e-5)\n",
    "np.testing.assert_allclose(bioAgeTrainM,    bioAgeTrainM_R,    rtol=1e-3, atol=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f1acbe84-84f2-47de-ada2-78de4f939f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Calculating BioAges for user data based on LinAge2 ... Females ... Males ... Done\n"
     ]
    }
   ],
   "source": [
    "print(\"> Calculating BioAges for user data based on LinAge2 ... \", end=\"\")\n",
    "## BioAge deltas and BioAge for user data set\n",
    "print(\"Females ... \", end=\"\")\n",
    "coxCovs_user_F = pd.DataFrame(coxCovs_user_F)\n",
    "#delBioAge_user_F = calcBioAge(coxModelF, nullModelF, coxCovs_user_F)\n",
    "delBioAge_user_F = calcBioAge_R_equiv(coxModelF, nullModelF, coxCovs_user_F,  coxCovsTrainF)\n",
    "                    \n",
    "bioAge_user_F = coxCovs_user_F[\"chronAge\"].values + delBioAge_user_F\n",
    "\n",
    "print(\"Males ... \", end=\"\")\n",
    "coxCovs_user_M = pd.DataFrame(coxCovs_user_M)\n",
    "#delBioAge_user_M = calcBioAge(coxModelM, nullModelM, coxCovs_user_M)\n",
    "delBioAge_user_M = calcBioAge_R_equiv(coxModelM, nullModelM, coxCovs_user_M,  coxCovsTrainM)\n",
    "bioAge_user_M = coxCovs_user_M[\"chronAge\"].values + delBioAge_user_M\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8bdd9c14-a9cf-4f93-9f64-c9aee5a2c898",
   "metadata": {},
   "outputs": [],
   "source": [
    "delBioAge_user_F_R = pd.read_csv(\"delBioAge_user_F_R.csv\").values.squeeze()\n",
    "bioAge_user_F_R    = pd.read_csv(\"bioAge_user_F_R.csv\").values.squeeze()\n",
    "\n",
    "delBioAge_user_M_R = pd.read_csv(\"delBioAge_user_M_R.csv\").values.squeeze()\n",
    "bioAge_user_M_R    = pd.read_csv(\"bioAge_user_M_R.csv\").values.squeeze()\n",
    "\n",
    "np.testing.assert_allclose(delBioAge_user_F, delBioAge_user_F_R, rtol=1e-3, atol=2e-5)\n",
    "np.testing.assert_allclose(bioAge_user_F,    bioAge_user_F_R,    rtol=1e-3, atol=2e-5)\n",
    "np.testing.assert_allclose(delBioAge_user_M, delBioAge_user_M_R, rtol=1e-3, atol=1e-1)\n",
    "np.testing.assert_allclose(bioAge_user_M,    bioAge_user_M_R,    rtol=1e-3, atol=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "fbad59fd-3fd7-4bb0-bfaf-ece75a6b71d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Sort BA into testing matrix ... for both sexesDone\n",
      "> Sort BA into training matrix ... for both sexesDone\n",
      "> Sort BA into user matrix ... for both sexes ... Done\n",
      "> Adding PCs and LinAge2 data to user data matrix ...  > Sanity check passed \n",
      "Done\n",
      "#################################################################################\n",
      "> Data for SEQs:\n",
      "\n",
      "  [8881. 9106.]\n",
      "\n",
      "\n",
      "  added to the data matrix\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "> Enter SEQ Nr. to investigate single SEQ (enter zero to exit)\n",
      ">  9106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SEQ: 9106 has chronological age 72.33 and LinAge2 64.36\n",
      "> Writing updated user data matrix ... <userData_out.csv>\n",
      "Done\n",
      "<<< \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Sort BA estimates back into the (mixed sex) testing data matrix (testing data)\n",
    "print(\"> Sort BA into testing matrix ... for both sexes\", end=\"\")\n",
    "nTest = demoTest.shape[0]\n",
    "bioAge = np.zeros(nTest)\n",
    "chrAge = demoTest[\"RIDAGEEX\"].values\n",
    "\n",
    "## Sort by SEQN\n",
    "SEQnF = demoTest.loc[testUseF, \"SEQN\"].values\n",
    "SEQnM = demoTest.loc[testUseM, \"SEQN\"].values\n",
    "bioAge[np.isin(demoTest[\"SEQN\"], SEQnF)] = bioAgeTestF\n",
    "bioAge[np.isin(demoTest[\"SEQN\"], SEQnM)] = bioAgeTestM\n",
    "print(\"Done\")\n",
    "\n",
    "## Sort BA estimates back into the (mixed sex) testing data matrix (training data)\n",
    "print(\"> Sort BA into training matrix ... for both sexes\", end=\"\")\n",
    "nTrain = demoTrain.shape[0]\n",
    "bioAge_train = np.zeros(nTrain)\n",
    "chrAge_train = demoTrain[\"RIDAGEEX\"].values\n",
    "\n",
    "## Sort by SEQN\n",
    "SEQnF_train = demoTrain.loc[trainUseF, \"SEQN\"].values\n",
    "SEQnM_train = demoTrain.loc[trainUseM, \"SEQN\"].values\n",
    "bioAge_train[np.isin(demoTrain[\"SEQN\"], SEQnF_train)] = bioAgeTrainF\n",
    "bioAge_train[np.isin(demoTrain[\"SEQN\"], SEQnM_train)] = bioAgeTrainM\n",
    "print(\"Done\")\n",
    "\n",
    "## Sort user data by SEQN\n",
    "print(\"> Sort BA into user matrix ... for both sexes ... \", end=\"\")\n",
    "bioAge_user = np.zeros(userDataMat.shape[0])\n",
    "SEQnF_user = qDataMat_user.loc[qDataMat_user[\"RIAGENDR\"] == 2, \"SEQN\"].values\n",
    "SEQnM_user = qDataMat_user.loc[qDataMat_user[\"RIAGENDR\"] == 1, \"SEQN\"].values\n",
    "print(\"Done\")\n",
    "\n",
    "print(\"> Adding PCs and LinAge2 data to user data matrix ... \", end=\"\")\n",
    "bioAge_user[np.isin(qDataMat_user[\"SEQN\"], SEQnF_user)] = bioAge_user_F\n",
    "bioAge_user[np.isin(qDataMat_user[\"SEQN\"], SEQnM_user)] = bioAge_user_M\n",
    "outMat = userDataOut()\n",
    "print(\"Done\")\n",
    "\n",
    "## All done\n",
    "print(\"#################################################################################\")\n",
    "\n",
    "## Have a quick look at the output data and investigate individual SEQ\n",
    "userSEQs = outMat[\"SEQN\"].values\n",
    "print(\"> Data for SEQs:\\n\\n  \", end=\"\")\n",
    "print(userSEQs)\n",
    "print(\"\\n\\n  added to the data matrix\")\n",
    "\n",
    "SEQnr = userSEQs[0]\n",
    "while SEQnr != 0:\n",
    "    SEQnr = input(\"\\n> Enter SEQ Nr. to investigate single SEQ (enter zero to exit)\\n> \")\n",
    "    try:\n",
    "        SEQnr = int(SEQnr)\n",
    "        rowNr = np.where(userSEQs == SEQnr)[0]\n",
    "        if SEQnr > 0 and len(rowNr) == 0:\n",
    "            print(\">>> No such SEQ! \")\n",
    "        else:\n",
    "            if SEQnr > 0:\n",
    "                print(f\"> SEQ: {SEQnr} has chronological age {outMat.iloc[rowNr[0]]['chronAge']} and LinAge2 {outMat.iloc[rowNr[0]]['linAge2']}\")\n",
    "                cols = plotBars(outMat, SEQnr)\n",
    "                print(\"> Plotting PCs ... \", end=\"\")\n",
    "                plt.show()\n",
    "                print(\"Done\")\n",
    "    except:\n",
    "        break\n",
    "\n",
    "## Write out the user data matrix with added bioAge and sex-specific PC data\n",
    "print(\"> Writing updated user data matrix ... <userData_out.csv>\")\n",
    "outMat.to_csv(\"userData_out.csv\", index=False)\n",
    "print(\"Done\")\n",
    "\n",
    "print(\"<<< \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e00c9f-3f26-4c20-87d6-5c303de91298",
   "metadata": {},
   "outputs": [],
   "source": [
    "svCut = 42\n",
    "pcDatMat = pcDatMat.iloc[:, :svCut]\n",
    "xTestPCA = pcDatMat[testSam].values\n",
    "coxCovsTest = np.column_stack([initAgeTest, xTestPCA, sexTest])\n",
    "coxCovsTest = pd.DataFrame(coxCovsTest, columns=['chronAge'] + list(pcDatMat.columns) + ['sex'])\n",
    "coxCovsTestF = coxCovsTest[testUseF].reset_index(drop=True)\n",
    "delBioAgeTestF  = calcBioAge_R_equiv(coxModelF, nullModelF, coxCovsTestF, coxCovsTrainF)\n",
    "bioAgeTestF  = coxCovsTestF[\"chronAge\"].to_numpy()  + delBioAgeTestF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eac19f4-09bd-45bf-bc63-6a0f98d0d54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Visualization/interpretation things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "5c7c7dcf-a594-4922-a37b-297020b253fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_indices = [int(x[2:])-1 for x in coxModelF.feature_names_in_ if 'PC' in x]\n",
    "\n",
    "beta_full = np.zeros(59)\n",
    "beta_full[pc_indices] = coxModelF.coef_[1:]\n",
    "beta_age_null = nullModelF.coef_[0]\n",
    "\n",
    "beta_age_full = coxModelF.coef_[0]\n",
    "\n",
    "w_feature_years = (vMatDat99_F @ beta_full)/beta_age_null\n",
    "\n",
    "w_age = (beta_age_full / beta_age_null) - 1.0\n",
    "\n",
    "\n",
    "\n",
    "mu_PC = np.zeros(59)\n",
    "mu_PC[pc_indices] = coxCovsTrainF.mean().loc[coxModelF.feature_names_in_].iloc[1:].values\n",
    "mu_age = coxCovsTrainF['chronAge'].mean()\n",
    "\n",
    "mu_Z = mu_PC@vMatDat99_F.T\n",
    "\n",
    "Z_centered = inputMat01_F - mu_Z      # shape (n_samples, n_features)\n",
    "term_features = (Z_centered @ w_feature_years)\n",
    "term_age = (initAgeTest[testUseF] - mu_age) * w_age\n",
    "\n",
    "alt_delta = term_features + term_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "53a05cf3-63d6-4ce8-b02f-55339198d857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  22.10601287, -156.34463354,  -80.1681015 , ..., -121.90422265,\n",
       "       -100.67122011,  -67.62136943])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "fcc2693d-0c2c-4001-bc9c-c189db109fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x739966272e90>"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((Z_centered * w_feature_years)[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c2a404-9eed-47df-be7d-fb1a1929373b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
